{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a98030af-fcd1-4d63-a36e-38ba053498fa",
   "metadata": {},
   "source": [
    "# Business Usecase\n",
    "\n",
    "## Publish a Company Brochure\n",
    "\n",
    "This product will provide a brochure for the company based on the website URL, to provide a consice and well formatted information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5b08506-dc8b-4443-9201-5f1848161363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "# If these fail, please check you're running from an 'activated' environment with (llms) in the command prompt\n",
    "\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display, update_display\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc5d8880-f2ee-4c06-af16-ecbc0262af61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key looks good so far\n"
     ]
    }
   ],
   "source": [
    "# Initialize and constants\n",
    "\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if api_key and api_key.startswith('sk-proj-') and len(api_key)>10:\n",
    "    print(\"API key looks good so far\")\n",
    "else:\n",
    "    print(\"There might be a problem with your API key? \")\n",
    "    \n",
    "MODEL = 'gpt-4o-mini'\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "106dd65e-90af-4ca8-86b6-23a41840645b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A class to represent a Webpage\n",
    "\n",
    "# Some websites need you to use proper headers when fetching them:\n",
    "headers = {\n",
    " \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "class Website:\n",
    "    \"\"\"\n",
    "    A utility class to represent a Website that we have scraped, now with links\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "        response = requests.get(url, headers=headers)\n",
    "        self.body = response.content\n",
    "        soup = BeautifulSoup(self.body, 'html.parser')\n",
    "        self.title = soup.title.string if soup.title else \"No title found\"\n",
    "        if soup.body:\n",
    "            for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "                irrelevant.decompose()\n",
    "            self.text = soup.body.get_text(separator=\"\\n\", strip=True)\n",
    "        else:\n",
    "            self.text = \"\"\n",
    "        links = [link.get('href') for link in soup.find_all('a')]\n",
    "        self.links = [link for link in links if link]\n",
    "\n",
    "    def get_contents(self):\n",
    "        return f\"Webpage Title:\\n{self.title}\\nWebpage Contents:\\n{self.text}\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e30d8128-933b-44cc-81c8-ab4c9d86589a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.nvidia.com',\n",
       " '#page-content',\n",
       " 'https://www.nvidia.com/en-us/',\n",
       " 'https://www.nvidia.com/en-us/clara/biopharma/',\n",
       " 'https://www.nvidia.com/en-us/data-center/dgx-cloud/',\n",
       " 'https://www.nvidia.com/en-us/gpu-cloud/nemo-llm-service/',\n",
       " 'https://www.nvidia.com/en-us/omniverse/cloud/',\n",
       " 'https://docs.nvidia.com/ngc/gpu-cloud/ngc-private-registry-user-guide/index.html',\n",
       " 'https://www.nvidia.com/en-us/gpu-cloud/',\n",
       " 'https://www.nvidia.com/en-us/data-center/',\n",
       " 'https://www.nvidia.com/en-us/data-center/dgx-platform/',\n",
       " 'https://www.nvidia.com/en-us/data-center/grace-cpu/',\n",
       " 'https://www.nvidia.com/en-us/data-center/hgx/',\n",
       " 'https://www.nvidia.com/en-us/edge-computing/products/igx/',\n",
       " 'https://www.nvidia.com/en-us/data-center/products/mgx/',\n",
       " 'https://www.nvidia.com/en-us/data-center/products/ovx/',\n",
       " 'https://www.nvidia.com/en-us/autonomous-machines/embedded-systems/',\n",
       " 'https://www.nvidia.com/en-us/solutions/autonomous-vehicles/in-vehicle-computing/',\n",
       " 'https://www.nvidia.com/en-us/clara/medical-devices/',\n",
       " 'https://www.nvidia.com/en-us/geforce/',\n",
       " 'https://www.nvidia.com/en-us/geforce/graphics-cards/',\n",
       " 'https://www.nvidia.com/en-us/geforce/laptops/',\n",
       " 'https://www.nvidia.com/en-us/geforce/products/g-sync-monitors/',\n",
       " 'https://www.nvidia.com/en-us/geforce/technologies/dlss/',\n",
       " 'https://www.nvidia.com/en-us/geforce/technologies/reflex/',\n",
       " 'https://www.nvidia.com/en-us/ai-on-rtx/',\n",
       " 'https://www.nvidia.com/en-us/studio/laptops-desktops/',\n",
       " 'https://www.nvidia.com/en-us/geforce-now/',\n",
       " 'https://www.nvidia.com/en-us/software/nvidia-app/',\n",
       " 'https://www.nvidia.com/en-us/geforce/broadcasting/',\n",
       " 'https://www.nvidia.com/en-us/shield/',\n",
       " 'https://www.nvidia.com/en-us/data-center/technologies/blackwell-architecture/',\n",
       " 'https://www.nvidia.com/en-us/data-center/technologies/hopper-architecture/',\n",
       " 'https://www.nvidia.com/en-us/technologies/ada-architecture/',\n",
       " 'https://www.nvidia.com/en-us/geforce/graphics-cards/',\n",
       " 'https://www.nvidia.com/en-us/products/workstations/',\n",
       " 'https://www.nvidia.com/en-us/data-center/virtual-solutions/',\n",
       " 'https://www.nvidia.com/en-us/geforce/laptops/',\n",
       " 'https://www.nvidia.com/en-us/studio/laptops-desktops/',\n",
       " 'https://www.nvidia.com/en-us/products/workstations/professional-laptops/',\n",
       " 'https://www.nvidia.com/en-us/networking/',\n",
       " 'https://www.nvidia.com/en-us/networking/products/data-processing-unit/',\n",
       " 'https://www.nvidia.com/en-us/networking/products/ethernet/',\n",
       " 'https://www.nvidia.com/en-us/networking/products/infiniband/',\n",
       " 'https://www.nvidia.com/en-us/networking/products/software/',\n",
       " 'https://www.nvidia.com/en-us/data-center/magnum-io/',\n",
       " 'https://www.nvidia.com/en-us/products/workstations/',\n",
       " 'https://www.nvidia.com/en-us/products/workstations/dgx-spark/',\n",
       " 'https://www.nvidia.com/en-us/products/workstations/dgx-station/',\n",
       " 'https://www.nvidia.com/en-us/products/workstations/ai-workstations/',\n",
       " 'https://www.nvidia.com/en-us/products/workstations/professional-desktop-gpus/',\n",
       " 'https://www.nvidia.com/en-us/products/workstations/professional-laptops/',\n",
       " 'https://developer.nvidia.com/agentiq',\n",
       " 'https://build.nvidia.com/blueprints',\n",
       " 'https://www.nvidia.com/en-us/ai/dynamo/',\n",
       " 'https://www.nvidia.com/en-us/ai-data-science/products/nim-microservices/',\n",
       " 'https://www.nvidia.com/en-us/technologies/cuda-x/',\n",
       " 'https://www.nvidia.com/en-us/self-driving-cars/in-vehicle-computing/',\n",
       " 'https://developer.nvidia.com/ace/tokkio-showcase',\n",
       " 'https://developer.nvidia.com/MAXINE',\n",
       " 'https://www.nvidia.com/en-us/ai-data-science/products/morpheus/',\n",
       " 'https://www.nvidia.com/en-us/deep-learning-ai/solutions/data-science/apache-spark-3/',\n",
       " 'https://developer.nvidia.com/rapids/',\n",
       " 'https://www.nvidia.com/en-us/ai-data-science/products/cuopt/',\n",
       " 'https://www.nvidia.com/en-us/ai-data-science/products/nemo/',\n",
       " 'https://www.nvidia.com/en-us/clara/',\n",
       " 'https://www.nvidia.com/en-us/omniverse/',\n",
       " 'https://www.nvidia.com/en-us/autonomous-machines/intelligent-video-analytics-platform/',\n",
       " 'https://www.nvidia.com/en-us/data-center/mission-control/',\n",
       " 'https://www.nvidia.com/en-us/data-center/products/ai-enterprise/',\n",
       " 'https://www.nvidia.com/en-us/ai/cosmos/',\n",
       " 'https://www.nvidia.com/en-us/software/run-ai/',\n",
       " 'https://developer.nvidia.com/isaac/ros',\n",
       " 'https://developer.nvidia.com/aerial',\n",
       " 'https://www.nvidia.com/en-us/software/',\n",
       " 'https://www.nvidia.com/en-us/deep-learning-ai/solutions/data-science/workbench/',\n",
       " 'https://build.nvidia.com/explore/discover',\n",
       " 'https://www.nvidia.com/en-us/data-center/enterprise-software/',\n",
       " 'https://developer.nvidia.com/dcgm',\n",
       " 'https://developer.nvidia.com/tools-overview',\n",
       " 'https://catalog.ngc.nvidia.com/',\n",
       " 'https://www.nvidia.com/en-us/software/nvidia-app-enterprise/',\n",
       " 'https://www.nvidia.com/en-us/gpu-cloud/',\n",
       " 'https://www.nvidia.com/en-us/software/rtx-desktop-manager/',\n",
       " 'https://www.nvidia.com/en-us/studio/software/',\n",
       " 'https://www.nvidia.com/en-us/design-visualization/software/broadcast-app/',\n",
       " 'https://www.nvidia.com/en-us/solutions/ai/',\n",
       " 'https://www.nvidia.com/en-us/ai/',\n",
       " 'https://www.nvidia.com/en-us/data-center/ai-data-platform/',\n",
       " 'https://www.nvidia.com/en-us/solutions/ai/conversational-ai/',\n",
       " 'https://www.nvidia.com/en-us/solutions/ai/cybersecurity/',\n",
       " 'https://www.nvidia.com/en-us/deep-learning-ai/solutions/data-science/',\n",
       " 'https://www.nvidia.com/en-us/solutions/ai/generative-ai/',\n",
       " 'https://www.nvidia.com/en-us/solutions/ai/inference/',\n",
       " 'https://www.nvidia.com/en-us/data-center/',\n",
       " 'https://www.nvidia.com/en-us/data-center/ai-data-platform/',\n",
       " 'https://www.nvidia.com/en-us/data-center/solutions/accelerated-computing/',\n",
       " 'https://www.nvidia.com/en-us/data-center/gpu-cloud-computing/',\n",
       " 'https://www.nvidia.com/en-us/data-center/colocation-partners/',\n",
       " 'https://www.nvidia.com/en-us/data-center/solutions/mlops/',\n",
       " 'https://www.nvidia.com/en-us/networking/',\n",
       " 'https://www.nvidia.com/en-us/data-center/sustainable-computing/',\n",
       " 'https://www.nvidia.com/en-us/data-center/virtual-solutions/',\n",
       " 'https://www.nvidia.com/en-us/solutions/design-and-simulation/',\n",
       " 'https://www.nvidia.com/en-us/solutions/cae/',\n",
       " 'https://www.nvidia.com/en-us/glossary/digital-twin/',\n",
       " 'https://www.nvidia.com/en-us/solutions/rendering/',\n",
       " 'https://www.nvidia.com/en-us/solutions/robotics-and-edge-computing/',\n",
       " 'https://www.nvidia.com/en-us/high-performance-computing/scientific-visualization/',\n",
       " 'https://www.nvidia.com/en-us/solutions/autonomous-vehicles/',\n",
       " 'https://www.nvidia.com/en-us/design-visualization/solutions/virtual-reality/',\n",
       " 'https://www.nvidia.com/en-us/high-performance-computing/',\n",
       " 'https://www.nvidia.com/en-us/high-performance-computing/hpc-and-ai/',\n",
       " 'https://www.nvidia.com/en-us/high-performance-computing/scientific-visualization/',\n",
       " 'https://www.nvidia.com/en-us/high-performance-computing/simulation-and-modeling/',\n",
       " 'https://www.nvidia.com/en-us/solutions/quantum-computing/',\n",
       " 'https://www.nvidia.com/en-us/solutions/robotics-and-edge-computing/',\n",
       " 'https://www.nvidia.com/en-us/industries/robotics/',\n",
       " 'https://www.nvidia.com/en-us/edge-computing/',\n",
       " 'https://www.nvidia.com/en-us/autonomous-machines/intelligent-video-analytics-platform/',\n",
       " 'https://www.nvidia.com/en-us/solutions/autonomous-vehicles/',\n",
       " 'https://www.nvidia.com/en-us/solutions/autonomous-vehicles/ai-training/',\n",
       " 'https://www.nvidia.com/en-us/use-cases/autonomous-vehicle-simulation/',\n",
       " 'https://www.nvidia.com/en-us/solutions/autonomous-vehicles/in-vehicle-computing/',\n",
       " 'https://www.nvidia.com/en-us/solutions/autonomous-vehicles/safety/',\n",
       " 'https://www.nvidia.com/en-us/industries/',\n",
       " 'https://www.nvidia.com/en-us/industries/aec/',\n",
       " 'https://www.nvidia.com/en-us/industries/automotive/',\n",
       " 'https://www.nvidia.com/en-us/industries/consumer-internet/',\n",
       " 'https://www.nvidia.com/en-us/solutions/ai/cybersecurity/',\n",
       " 'https://www.nvidia.com/en-us/industries/energy/',\n",
       " 'https://www.nvidia.com/en-us/industries/finance/',\n",
       " 'https://www.nvidia.com/en-us/industries/healthcare-life-sciences/',\n",
       " 'https://www.nvidia.com/en-us/industries/higher-education-research/',\n",
       " 'https://www.nvidia.com/en-us/industries/game-development/',\n",
       " 'https://www.nvidia.com/en-us/industries/global-public-sector/',\n",
       " 'https://www.nvidia.com/en-us/industries/manufacturing/',\n",
       " 'https://www.nvidia.com/en-us/industries/media-and-entertainment/',\n",
       " 'https://www.nvidia.com/en-us/industries/public-sector/',\n",
       " 'https://www.nvidia.com/en-us/industries/restaurants/',\n",
       " 'https://www.nvidia.com/en-us/industries/retail/',\n",
       " 'https://www.nvidia.com/en-us/industries/robotics/',\n",
       " 'https://www.nvidia.com/en-us/industries/smart-cities-and-spaces/',\n",
       " 'https://www.nvidia.com/en-us/industries/supercomputing/',\n",
       " 'https://www.nvidia.com/en-us/industries/telecommunications/',\n",
       " 'https://www.nvidia.com/en-us/industries/transportation/',\n",
       " 'https://marketplace.nvidia.com/en-us/',\n",
       " 'https://www.nvidia.com/en-us/drivers/',\n",
       " 'https://www.nvidia.com/en-us/support/',\n",
       " '#',\n",
       " '#',\n",
       " '#',\n",
       " 'https://www.nvidia.com/en-us/account/',\n",
       " '#',\n",
       " '#',\n",
       " '#page-content',\n",
       " '#',\n",
       " '#',\n",
       " 'https://www.nvidia.com/en-us/',\n",
       " '/',\n",
       " '#',\n",
       " 'https://www.nvidia.com/en-us/account/',\n",
       " '#',\n",
       " '#',\n",
       " 'https://www.nvidia.com/en-us/clara/biopharma/',\n",
       " 'https://www.nvidia.com/en-us/data-center/dgx-cloud/',\n",
       " 'https://www.nvidia.com/en-us/gpu-cloud/nemo-llm-service/',\n",
       " 'https://www.nvidia.com/en-us/omniverse/cloud/',\n",
       " 'https://docs.nvidia.com/ngc/gpu-cloud/ngc-private-registry-user-guide/index.html',\n",
       " 'https://www.nvidia.com/en-us/gpu-cloud/',\n",
       " 'https://www.nvidia.com/en-us/data-center/',\n",
       " 'https://www.nvidia.com/en-us/data-center/dgx-platform/',\n",
       " 'https://www.nvidia.com/en-us/data-center/grace-cpu/',\n",
       " 'https://www.nvidia.com/en-us/data-center/hgx/',\n",
       " 'https://www.nvidia.com/en-us/edge-computing/products/igx/',\n",
       " 'https://www.nvidia.com/en-us/data-center/products/mgx/',\n",
       " 'https://www.nvidia.com/en-us/data-center/products/ovx/',\n",
       " 'https://www.nvidia.com/en-us/autonomous-machines/embedded-systems/',\n",
       " 'https://www.nvidia.com/en-us/solutions/autonomous-vehicles/in-vehicle-computing/',\n",
       " 'https://www.nvidia.com/en-us/clara/medical-devices/',\n",
       " 'https://www.nvidia.com/en-us/geforce/',\n",
       " 'https://www.nvidia.com/en-us/geforce/graphics-cards/',\n",
       " 'https://www.nvidia.com/en-us/geforce/laptops/',\n",
       " 'https://www.nvidia.com/en-us/geforce/products/g-sync-monitors/',\n",
       " 'https://www.nvidia.com/en-us/geforce/technologies/dlss/',\n",
       " 'https://www.nvidia.com/en-us/geforce/technologies/reflex/',\n",
       " 'https://www.nvidia.com/en-us/ai-on-rtx/',\n",
       " 'https://www.nvidia.com/en-us/studio/laptops-desktops/',\n",
       " 'https://www.nvidia.com/en-us/geforce-now/',\n",
       " 'https://www.nvidia.com/en-us/software/nvidia-app/',\n",
       " 'https://www.nvidia.com/en-us/geforce/broadcasting/',\n",
       " 'https://www.nvidia.com/en-us/shield/',\n",
       " 'https://www.nvidia.com/en-us/data-center/technologies/blackwell-architecture/',\n",
       " 'https://www.nvidia.com/en-us/data-center/technologies/hopper-architecture/',\n",
       " 'https://www.nvidia.com/en-us/technologies/ada-architecture/',\n",
       " 'https://www.nvidia.com/en-us/geforce/graphics-cards/',\n",
       " 'https://www.nvidia.com/en-us/products/workstations/',\n",
       " 'https://www.nvidia.com/en-us/data-center/virtual-solutions/',\n",
       " 'https://www.nvidia.com/en-us/geforce/laptops/',\n",
       " 'https://www.nvidia.com/en-us/studio/laptops-desktops/',\n",
       " 'https://www.nvidia.com/en-us/products/workstations/professional-laptops/',\n",
       " 'https://www.nvidia.com/en-us/networking/',\n",
       " 'https://www.nvidia.com/en-us/networking/products/data-processing-unit/',\n",
       " 'https://www.nvidia.com/en-us/networking/products/ethernet/',\n",
       " 'https://www.nvidia.com/en-us/networking/products/infiniband/',\n",
       " 'https://www.nvidia.com/en-us/networking/products/software/',\n",
       " 'https://www.nvidia.com/en-us/data-center/magnum-io/',\n",
       " 'https://www.nvidia.com/en-us/products/workstations/',\n",
       " 'https://www.nvidia.com/en-us/products/workstations/dgx-spark/',\n",
       " 'https://www.nvidia.com/en-us/products/workstations/dgx-station/',\n",
       " 'https://www.nvidia.com/en-us/products/workstations/ai-workstations/',\n",
       " 'https://www.nvidia.com/en-us/products/workstations/professional-desktop-gpus/',\n",
       " 'https://www.nvidia.com/en-us/products/workstations/professional-laptops/',\n",
       " 'https://developer.nvidia.com/agentiq',\n",
       " 'https://build.nvidia.com/blueprints',\n",
       " 'https://www.nvidia.com/en-us/ai/dynamo/',\n",
       " 'https://www.nvidia.com/en-us/ai-data-science/products/nim-microservices/',\n",
       " 'https://www.nvidia.com/en-us/technologies/cuda-x/',\n",
       " 'https://www.nvidia.com/en-us/self-driving-cars/in-vehicle-computing/',\n",
       " 'https://developer.nvidia.com/ace/tokkio-showcase',\n",
       " 'https://developer.nvidia.com/MAXINE',\n",
       " 'https://www.nvidia.com/en-us/ai-data-science/products/morpheus/',\n",
       " 'https://www.nvidia.com/en-us/deep-learning-ai/solutions/data-science/apache-spark-3/',\n",
       " 'https://developer.nvidia.com/rapids/',\n",
       " 'https://www.nvidia.com/en-us/ai-data-science/products/cuopt/',\n",
       " 'https://www.nvidia.com/en-us/ai-data-science/products/nemo/',\n",
       " 'https://www.nvidia.com/en-us/clara/',\n",
       " 'https://www.nvidia.com/en-us/omniverse/',\n",
       " 'https://www.nvidia.com/en-us/autonomous-machines/intelligent-video-analytics-platform/',\n",
       " 'https://www.nvidia.com/en-us/data-center/mission-control/',\n",
       " 'https://www.nvidia.com/en-us/data-center/products/ai-enterprise/',\n",
       " 'https://www.nvidia.com/en-us/ai/cosmos/',\n",
       " 'https://www.nvidia.com/en-us/software/run-ai/',\n",
       " 'https://developer.nvidia.com/isaac/ros',\n",
       " 'https://developer.nvidia.com/aerial',\n",
       " 'https://www.nvidia.com/en-us/software/',\n",
       " 'https://www.nvidia.com/en-us/deep-learning-ai/solutions/data-science/workbench/',\n",
       " 'https://build.nvidia.com/explore/discover',\n",
       " 'https://www.nvidia.com/en-us/data-center/enterprise-software/',\n",
       " 'https://developer.nvidia.com/dcgm',\n",
       " 'https://developer.nvidia.com/tools-overview',\n",
       " 'https://catalog.ngc.nvidia.com/',\n",
       " 'https://www.nvidia.com/en-us/software/nvidia-app-enterprise/',\n",
       " 'https://www.nvidia.com/en-us/gpu-cloud/',\n",
       " 'https://www.nvidia.com/en-us/software/rtx-desktop-manager/',\n",
       " 'https://www.nvidia.com/en-us/studio/software/',\n",
       " 'https://www.nvidia.com/en-us/design-visualization/software/broadcast-app/',\n",
       " 'https://www.nvidia.com/en-us/solutions/ai/',\n",
       " 'https://www.nvidia.com/en-us/ai/',\n",
       " 'https://www.nvidia.com/en-us/data-center/ai-data-platform/',\n",
       " 'https://www.nvidia.com/en-us/solutions/ai/conversational-ai/',\n",
       " 'https://www.nvidia.com/en-us/solutions/ai/cybersecurity/',\n",
       " 'https://www.nvidia.com/en-us/deep-learning-ai/solutions/data-science/',\n",
       " 'https://www.nvidia.com/en-us/solutions/ai/generative-ai/',\n",
       " 'https://www.nvidia.com/en-us/solutions/ai/inference/',\n",
       " 'https://www.nvidia.com/en-us/data-center/',\n",
       " 'https://www.nvidia.com/en-us/data-center/ai-data-platform/',\n",
       " 'https://www.nvidia.com/en-us/data-center/solutions/accelerated-computing/',\n",
       " 'https://www.nvidia.com/en-us/data-center/gpu-cloud-computing/',\n",
       " 'https://www.nvidia.com/en-us/data-center/colocation-partners/',\n",
       " 'https://www.nvidia.com/en-us/data-center/solutions/mlops/',\n",
       " 'https://www.nvidia.com/en-us/networking/',\n",
       " 'https://www.nvidia.com/en-us/data-center/sustainable-computing/',\n",
       " 'https://www.nvidia.com/en-us/data-center/virtual-solutions/',\n",
       " 'https://www.nvidia.com/en-us/solutions/design-and-simulation/',\n",
       " 'https://www.nvidia.com/en-us/solutions/cae/',\n",
       " 'https://www.nvidia.com/en-us/glossary/digital-twin/',\n",
       " 'https://www.nvidia.com/en-us/solutions/rendering/',\n",
       " 'https://www.nvidia.com/en-us/solutions/robotics-and-edge-computing/',\n",
       " 'https://www.nvidia.com/en-us/high-performance-computing/scientific-visualization/',\n",
       " 'https://www.nvidia.com/en-us/solutions/autonomous-vehicles/',\n",
       " 'https://www.nvidia.com/en-us/design-visualization/solutions/virtual-reality/',\n",
       " 'https://www.nvidia.com/en-us/high-performance-computing/',\n",
       " 'https://www.nvidia.com/en-us/high-performance-computing/hpc-and-ai/',\n",
       " 'https://www.nvidia.com/en-us/high-performance-computing/scientific-visualization/',\n",
       " 'https://www.nvidia.com/en-us/high-performance-computing/simulation-and-modeling/',\n",
       " 'https://www.nvidia.com/en-us/solutions/quantum-computing/',\n",
       " 'https://www.nvidia.com/en-us/solutions/robotics-and-edge-computing/',\n",
       " 'https://www.nvidia.com/en-us/industries/robotics/',\n",
       " 'https://www.nvidia.com/en-us/edge-computing/',\n",
       " 'https://www.nvidia.com/en-us/autonomous-machines/intelligent-video-analytics-platform/',\n",
       " 'https://www.nvidia.com/en-us/solutions/autonomous-vehicles/',\n",
       " 'https://www.nvidia.com/en-us/solutions/autonomous-vehicles/ai-training/',\n",
       " 'https://www.nvidia.com/en-us/use-cases/autonomous-vehicle-simulation/',\n",
       " 'https://www.nvidia.com/en-us/solutions/autonomous-vehicles/in-vehicle-computing/',\n",
       " 'https://www.nvidia.com/en-us/solutions/autonomous-vehicles/safety/',\n",
       " 'https://www.nvidia.com/en-us/industries/',\n",
       " 'https://www.nvidia.com/en-us/industries/aec/',\n",
       " 'https://www.nvidia.com/en-us/industries/automotive/',\n",
       " 'https://www.nvidia.com/en-us/industries/consumer-internet/',\n",
       " 'https://www.nvidia.com/en-us/solutions/ai/cybersecurity/',\n",
       " 'https://www.nvidia.com/en-us/industries/energy/',\n",
       " 'https://www.nvidia.com/en-us/industries/finance/',\n",
       " 'https://www.nvidia.com/en-us/industries/healthcare-life-sciences/',\n",
       " 'https://www.nvidia.com/en-us/industries/higher-education-research/',\n",
       " 'https://www.nvidia.com/en-us/industries/game-development/',\n",
       " 'https://www.nvidia.com/en-us/industries/global-public-sector/',\n",
       " 'https://www.nvidia.com/en-us/industries/manufacturing/',\n",
       " 'https://www.nvidia.com/en-us/industries/media-and-entertainment/',\n",
       " 'https://www.nvidia.com/en-us/industries/public-sector/',\n",
       " 'https://www.nvidia.com/en-us/industries/restaurants/',\n",
       " 'https://www.nvidia.com/en-us/industries/retail/',\n",
       " 'https://www.nvidia.com/en-us/industries/robotics/',\n",
       " 'https://www.nvidia.com/en-us/industries/smart-cities-and-spaces/',\n",
       " 'https://www.nvidia.com/en-us/industries/supercomputing/',\n",
       " 'https://www.nvidia.com/en-us/industries/telecommunications/',\n",
       " 'https://www.nvidia.com/en-us/industries/transportation/',\n",
       " 'https://marketplace.nvidia.com/en-us/',\n",
       " 'https://www.nvidia.com/en-us/drivers/',\n",
       " 'https://www.nvidia.com/en-us/support/',\n",
       " 'http://www.enable-javascript.com/',\n",
       " 'https://blogs.nvidia.com/blog/hpe-nvidia-ai-factory',\n",
       " 'https://eventmobi.com/website/coreweave',\n",
       " 'https://www.nvidia.com/en-eu/gtc/keynote/',\n",
       " 'https://blogs.nvidia.com/blog/auto-research-cvpr-2025/',\n",
       " 'https://nvidianews.nvidia.com/news/europe-ai-infrastructure',\n",
       " 'https://nvidianews.nvidia.com/news/nvidia-partners-with-europe-model-builders-and-cloud-providers-to-accelerate-regions-leap-into-ai',\n",
       " 'https://www.nvidia.com/en-eu/gtc/keynote/',\n",
       " 'https://www.nvidia.com/en-us/ai-data-science/',\n",
       " 'https://www.nvidia.com/en-us/deep-learning-ai/solutions/data-analytics/',\n",
       " 'https://www.nvidia.com/en-us/deep-learning-ai/solutions/machine-learning/',\n",
       " 'https://www.nvidia.com/en-us/deep-learning-ai/solutions/prediction-forecasting/',\n",
       " 'https://developer.nvidia.com/nvidia-merlin',\n",
       " 'https://www.nvidia.com/en-us/ai-data-science/products/riva/',\n",
       " 'https://www.nvidia.com/en-us/deep-learning-ai/solutions/data-science/apache-spark-3/',\n",
       " 'https://www.nvidia.com/en-us/deep-learning-ai/software/rapids/',\n",
       " 'https://www.nvidia.com/en-us/case-studies/shell-trains-custom-ai-chatbot-with-nemo/',\n",
       " 'https://www.nvidia.com/en-us/case-studies/shell-trains-custom-ai-chatbot-with-nemo/',\n",
       " 'https://www.nvidia.com/en-us/case-studies/linker-vision-ai-smart-city-solutions/',\n",
       " 'https://www.nvidia.com/en-us/case-studies/linker-vision-ai-smart-city-solutions/',\n",
       " 'https://blogs.nvidia.com/blog/europe-6g-research/',\n",
       " 'https://blogs.nvidia.com/blog/europe-6g-research/',\n",
       " 'https://blogs.nvidia.com/blog/france-sovereign-ai-infrastructure/',\n",
       " 'https://blogs.nvidia.com/blog/france-sovereign-ai-infrastructure/',\n",
       " 'https://blogs.nvidia.com/blog/sovereign-ai-agents-factories/',\n",
       " 'https://blogs.nvidia.com/blog/sovereign-ai-agents-factories/',\n",
       " 'https://blogs.nvidia.com/blog/europe-financial-services-ai/',\n",
       " 'https://blogs.nvidia.com/blog/europe-financial-services-ai/',\n",
       " 'https://blogs.nvidia.com/blog/european-broadcasting-union-sovereign-ai/',\n",
       " 'https://blogs.nvidia.com/blog/european-broadcasting-union-sovereign-ai/',\n",
       " 'https://blogs.nvidia.com/blog/retail-agentic-physical-ai/',\n",
       " 'https://blogs.nvidia.com/blog/retail-agentic-physical-ai/',\n",
       " 'https://blogs.nvidia.com/blog/ai-blueprint-telco-network-configuration/',\n",
       " 'https://blogs.nvidia.com/blog/ai-blueprint-telco-network-configuration/',\n",
       " 'https://blogs.nvidia.com/blog/rtx-ai-garage-fity-flex-flux-comfyui-stable-diffusion',\n",
       " 'https://blogs.nvidia.com/blog/rtx-ai-garage-fity-flex-flux-comfyui-stable-diffusion',\n",
       " 'https://store.nvidia.com/en-us/nvidia-rtx/store/?page=1&limit=9&locale=en-us',\n",
       " 'https://blogs.nvidia.com/blog/category/pro-graphics/',\n",
       " 'https://www.nvidia.com/en-us/design-visualization/',\n",
       " 'https://www.nvidia.com/en-us/omniverse/',\n",
       " 'https://developer.nvidia.com/rtx',\n",
       " 'https://www.nvidia.com/en-us/research/',\n",
       " 'https://www.nvidia.com/en-us/design-visualization/solutions/cloud-xr/',\n",
       " 'https://blogs.nvidia.com/blog/wfm-advance-av-sim-safety/',\n",
       " 'https://blogs.nvidia.com/blog/wfm-advance-av-sim-safety/',\n",
       " 'https://blogs.nvidia.com/blog/smart-city-ai-blueprint-europe',\n",
       " 'https://blogs.nvidia.com/blog/smart-city-ai-blueprint-europe',\n",
       " 'https://blogs.nvidia.com/blog/omniverse-digital-twins-taiwan-manufacturers-physical-ai',\n",
       " 'https://blogs.nvidia.com/blog/omniverse-digital-twins-taiwan-manufacturers-physical-ai',\n",
       " 'https://blogs.nvidia.com/blog/omniverse-blueprint-ai-factories-expands',\n",
       " 'https://blogs.nvidia.com/blog/omniverse-blueprint-ai-factories-expands',\n",
       " 'https://blogs.nvidia.com/blog/computational-fluid-dynamics-digital-twins/',\n",
       " 'https://blogs.nvidia.com/blog/computational-fluid-dynamics-digital-twins/',\n",
       " 'https://blogs.nvidia.com/blog/how-digital-twins-scale-industrial-ai',\n",
       " 'https://blogs.nvidia.com/blog/how-digital-twins-scale-industrial-ai',\n",
       " 'https://blogs.nvidia.com/blog/mega-omniverse-blueprint-industrial-digital-twins',\n",
       " 'https://blogs.nvidia.com/blog/mega-omniverse-blueprint-industrial-digital-twins',\n",
       " 'https://nvidianews.nvidia.com/news/nvidia-announces-major-release-of-cosmos-world-foundation-models-and-physical-ai-data-tools',\n",
       " 'https://nvidianews.nvidia.com/news/nvidia-announces-major-release-of-cosmos-world-foundation-models-and-physical-ai-data-tools',\n",
       " 'https://nvidianews.nvidia.com/news/nvidia-omniverse-physical-ai-operating-system-expands-to-more-industries-and-partners',\n",
       " 'https://nvidianews.nvidia.com/news/nvidia-omniverse-physical-ai-operating-system-expands-to-more-industries-and-partners',\n",
       " 'https://blogs.nvidia.com/blog/omniverse-blueprint-ai-factory/',\n",
       " 'https://blogs.nvidia.com/blog/omniverse-blueprint-ai-factory/',\n",
       " 'https://www.nvidia.com/en-us/high-performance-computing/',\n",
       " 'https://www.nvidia.com/en-us/events/supercomputing/',\n",
       " 'https://www.nvidia.com/en-us/lp/high-performance-computing/hpc-ai-cloud-computing-ebook/',\n",
       " 'https://www.nvidia.com/en-us/industries/healthcare-life-sciences/',\n",
       " 'https://www.nvidia.com/en-us/industries/public-sector/',\n",
       " 'https://www.nvidia.com/en-us/industries/energy/',\n",
       " 'https://developer.nvidia.com/hpc-sdk',\n",
       " 'https://developer.nvidia.com/physicsnemo',\n",
       " 'https://blogs.nvidia.com/blog/ansys-dcai-quantum-computing/',\n",
       " 'https://blogs.nvidia.com/blog/ansys-dcai-quantum-computing/',\n",
       " 'https://blogs.nvidia.com/blog/journey-to-quantum-computing/',\n",
       " 'https://blogs.nvidia.com/blog/journey-to-quantum-computing/',\n",
       " 'https://nvidianews.nvidia.com/news/nvidia-powers-europes-fastest-supercomputer',\n",
       " 'https://nvidianews.nvidia.com/news/nvidia-powers-europes-fastest-supercomputer',\n",
       " 'http://blogs.nvidia.com/blog/blue-lion-vera-rubin',\n",
       " 'http://blogs.nvidia.com/blog/blue-lion-vera-rubin',\n",
       " 'https://blogs.nvidia.com/blog/earth2-generative-ai-foundation-model-global-climate-kilometer-scale-resolution',\n",
       " 'https://blogs.nvidia.com/blog/earth2-generative-ai-foundation-model-global-climate-kilometer-scale-resolution',\n",
       " 'https://blogs.nvidia.com/blog/dell-nvidia-berkeley-doudna/',\n",
       " 'https://blogs.nvidia.com/blog/dell-nvidia-berkeley-doudna/',\n",
       " 'https://nvidianews.nvidia.com/news/nvidia-powers-worlds-largest-quantum-research-supercomputer',\n",
       " 'https://nvidianews.nvidia.com/news/nvidia-powers-worlds-largest-quantum-research-supercomputer',\n",
       " 'https://blogs.nvidia.com/blog/semiconductor-industry-electronic-design-automation-blackwell-cuda-x',\n",
       " 'https://blogs.nvidia.com/blog/semiconductor-industry-electronic-design-automation-blackwell-cuda-x',\n",
       " 'https://nvidianews.nvidia.com/news/nvidia-to-build-accelerated-quantum-computing-research-center',\n",
       " 'https://nvidianews.nvidia.com/news/nvidia-to-build-accelerated-quantum-computing-research-center',\n",
       " 'https://nvidianews.nvidia.com/news/nvidia-and-ge-healthcare-collaborate-to-advance-the-development-of-autonomous-diagnostic-imaging-with-physical-ai',\n",
       " 'https://nvidianews.nvidia.com/news/nvidia-and-ge-healthcare-collaborate-to-advance-the-development-of-autonomous-diagnostic-imaging-with-physical-ai',\n",
       " 'https://store.nvidia.com/en-us/geforce/store/?page=1&limit=9&locale=en-us',\n",
       " 'https://www.nvidia.com/en-us/geforce/',\n",
       " 'https://www.nvidia.com/en-us/geforce/graphics-cards/',\n",
       " 'https://www.nvidia.com/en-us/geforce/gaming-laptops/',\n",
       " 'https://www.nvidia.com/en-us/geforce/technologies/dlss/',\n",
       " 'https://www.nvidia.com/en-us/geforce/technologies/reflex/',\n",
       " 'https://www.nvidia.com/en-us/studio/',\n",
       " 'https://www.nvidia.com/en-us/geforce-now/',\n",
       " 'https://www.nvidia.com/en-us/software/nvidia-app/',\n",
       " 'https://www.nvidia.com/en-us/geforce/game-ready-drivers/',\n",
       " 'https://www.nvidia.com/en-us/geforce/products/g-sync-monitors/',\n",
       " 'https://www.nvidia.com/en-us/geforce/news/rtx-5060-out-now/',\n",
       " 'https://www.nvidia.com/en-us/geforce/news/rtx-5060-out-now/',\n",
       " 'https://www.nvidia.com/en-us/geforce/news/doom-the-dark-ages-path-tracing-dlss-ray-reconstruction-update/',\n",
       " 'https://www.nvidia.com/en-us/geforce/news/doom-the-dark-ages-path-tracing-dlss-ray-reconstruction-update/',\n",
       " 'https://www.nvidia.com/en-us/geforce/news/diablo-iv-strinova-eternal-strands-dlss-4-multi-frame-gen/',\n",
       " 'https://www.nvidia.com/en-us/geforce/news/diablo-iv-strinova-eternal-strands-dlss-4-multi-frame-gen/',\n",
       " 'https://www.nvidia.com/en-us/geforce/news/dune-awakening-dlss-4-multi-frame-generation-out-now/',\n",
       " 'https://www.nvidia.com/en-us/geforce/news/dune-awakening-dlss-4-multi-frame-generation-out-now/',\n",
       " 'https://www.nvidia.com/en-us/geforce/news/125-dlss-4-multi-frame-gen-games-more-announced-computex-2025/',\n",
       " 'https://www.nvidia.com/en-us/geforce/news/125-dlss-4-multi-frame-gen-games-more-announced-computex-2025/',\n",
       " 'https://www.nvidia.com/en-us/geforce/news/rtx-remix-mod-contest-portal-with-rtx-dlss-4-multi-frame-gen/',\n",
       " 'https://www.nvidia.com/en-us/geforce/news/rtx-remix-mod-contest-portal-with-rtx-dlss-4-multi-frame-gen/',\n",
       " 'https://www.nvidia.com/en-us/geforce/news/g-assist-ai-companion-for-rtx-ai-pcs/',\n",
       " 'https://www.nvidia.com/en-us/geforce/news/g-assist-ai-companion-for-rtx-ai-pcs/',\n",
       " 'https://www.nvidia.com/en-us/geforce/news/reflex-available-now-in-over-150-games/',\n",
       " 'https://www.nvidia.com/en-us/geforce/news/reflex-available-now-in-over-150-games/',\n",
       " 'https://blogs.nvidia.com/blog/geforce-now-thursday-elder-scrolls-online-member-reward',\n",
       " 'https://blogs.nvidia.com/blog/geforce-now-thursday-elder-scrolls-online-member-reward',\n",
       " 'https://blogs.nvidia.com/blog/rtx-ai-garage-g-assist-hackathon-plug-in',\n",
       " 'https://blogs.nvidia.com/blog/rtx-ai-garage-g-assist-hackathon-plug-in',\n",
       " 'https://www.nvidia.com/en-us/industries/automotive/',\n",
       " 'https://www.nvidia.com/en-us/self-driving-cars/',\n",
       " 'https://www.nvidia.com/en-us/self-driving-cars/in-vehicle-computing/',\n",
       " 'https://www.nvidia.com/en-us/self-driving-cars/ai-training/',\n",
       " 'https://www.nvidia.com/en-us/use-cases/autonomous-vehicle-simulation/',\n",
       " 'https://blogs.nvidia.com/blog/tag/av-podcast/',\n",
       " 'https://www.nvidia.com/en-us/self-driving-cars/drive-videos/',\n",
       " 'https://blogs.nvidia.com/blog/auto-research-cvpr-2025/',\n",
       " 'https://blogs.nvidia.com/blog/auto-research-cvpr-2025/',\n",
       " 'https://nvidianews.nvidia.com/news/general-motors-and-nvidia-collaborate-on-ai-for-next-generation-vehicle-experience-and-manufacturing',\n",
       " 'https://nvidianews.nvidia.com/news/general-motors-and-nvidia-collaborate-on-ai-for-next-generation-vehicle-experience-and-manufacturing',\n",
       " 'https://blogs.nvidia.com/blog/halos-safety-system-autonomous-vehicles/',\n",
       " 'https://blogs.nvidia.com/blog/halos-safety-system-autonomous-vehicles/',\n",
       " 'https://blogs.nvidia.com/blog/auto-ecosystem-physical-ai/',\n",
       " 'https://blogs.nvidia.com/blog/auto-ecosystem-physical-ai/',\n",
       " 'https://blogs.nvidia.com/blog/drive-partners-showcase-ces/',\n",
       " 'https://blogs.nvidia.com/blog/drive-partners-showcase-ces/',\n",
       " 'https://nvidianews.nvidia.com/news/nvidia-launches-cosmos-world-foundation-model-platform-to-accelerate-physical-ai-development',\n",
       " 'https://nvidianews.nvidia.com/news/nvidia-launches-cosmos-world-foundation-model-platform-to-accelerate-physical-ai-development',\n",
       " 'https://blogs.nvidia.com/blog/hyundai-motor-group-ces/',\n",
       " 'https://blogs.nvidia.com/blog/hyundai-motor-group-ces/',\n",
       " 'https://nvidianews.nvidia.com/news/toyota-aurora-continental-nvidia-drive',\n",
       " 'https://nvidianews.nvidia.com/news/toyota-aurora-continental-nvidia-drive',\n",
       " 'https://blogs.nvidia.com/blog/three-computer-cosmos-ces/',\n",
       " 'https://blogs.nvidia.com/blog/three-computer-cosmos-ces/',\n",
       " 'https://blogs.nvidia.com/blog/drive-ai-lab-ces/',\n",
       " 'https://blogs.nvidia.com/blog/drive-ai-lab-ces/',\n",
       " 'https://store.nvidia.com/en-us/jetson/store/?page=1&limit=9&locale=en-us',\n",
       " 'https://www.nvidia.com/en-us/edge-computing/',\n",
       " 'https://developer.nvidia.com/isaac',\n",
       " 'https://www.nvidia.com/en-us/autonomous-machines/',\n",
       " 'https://www.nvidia.com/en-us/research/robotics/',\n",
       " 'https://www.nvidia.com/en-us/autonomous-machines/',\n",
       " 'https://www.nvidia.com/en-us/edge-computing/products/igx/',\n",
       " 'https://www.nvidia.com/en-us/data-center/products/certified-systems/',\n",
       " 'https://developer.nvidia.com/embedded/ecosystem',\n",
       " 'https://blogs.nvidia.com/blog/hexagon-robotics-ai-software-aeon-humanoid',\n",
       " 'https://blogs.nvidia.com/blog/hexagon-robotics-ai-software-aeon-humanoid',\n",
       " 'https://blogs.nvidia.com/blog/european-robot-makers-isaac-omniverse-halos-safe-physical-ai',\n",
       " 'https://blogs.nvidia.com/blog/european-robot-makers-isaac-omniverse-halos-safe-physical-ai',\n",
       " 'https://blogs.nvidia.com/blog/foxconn-smart-hospital-robot/',\n",
       " 'https://blogs.nvidia.com/blog/foxconn-smart-hospital-robot/',\n",
       " 'https://developer.nvidia.com/blog/r2d2-unlocking-robotic-assembly-and-contact-rich-manipulation-with-nvidia-research/',\n",
       " 'https://developer.nvidia.com/blog/r2d2-unlocking-robotic-assembly-and-contact-rich-manipulation-with-nvidia-research/',\n",
       " 'https://blogs.nvidia.com/blog/nvidia-research-robotics-icra-2025/',\n",
       " 'https://blogs.nvidia.com/blog/nvidia-research-robotics-icra-2025/',\n",
       " 'https://nvidianews.nvidia.com/news/nvidia-powers-humanoid-robot-industry-with-cloud-to-robot-computing-platforms-for-physical-ai',\n",
       " 'https://nvidianews.nvidia.com/news/nvidia-powers-humanoid-robot-industry-with-cloud-to-robot-computing-platforms-for-physical-ai',\n",
       " 'https://developer.nvidia.com/blog/r%c2%b2d%c2%b2-adapting-dexterous-robots-with-nvidia-research-workflows-and-models/',\n",
       " 'https://developer.nvidia.com/blog/r%c2%b2d%c2%b2-adapting-dexterous-robots-with-nvidia-research-workflows-and-models/',\n",
       " 'https://blogs.nvidia.com/blog/national-robotics-week-2025/',\n",
       " 'https://blogs.nvidia.com/blog/national-robotics-week-2025/',\n",
       " 'https://developer.nvidia.com/blog/r2d2-advancing-robot-mobility-whole-body-control-with-ai-from-nvidia-research/',\n",
       " 'https://developer.nvidia.com/blog/r2d2-advancing-robot-mobility-whole-body-control-with-ai-from-nvidia-research/',\n",
       " 'https://nvidianews.nvidia.com/news/nvidia-releases-isaac-gr00t-n1-worlds-first-open-humanoid-robot-foundation-model-and-simulation-libraries',\n",
       " 'https://nvidianews.nvidia.com/news/nvidia-releases-isaac-gr00t-n1-worlds-first-open-humanoid-robot-foundation-model-and-simulation-libraries',\n",
       " 'https://www.nvidia.com/en-us/data-center/',\n",
       " 'https://www.nvidia.com/en-us/data-center/gpu-cloud-computing/',\n",
       " 'https://www.nvidia.com/en-us/edge-computing/',\n",
       " 'https://build.nvidia.com/explore/discover',\n",
       " 'https://www.nvidia.com/en-us/data-center/products/ai-enterprise/',\n",
       " 'https://www.nvidia.com/en-us/data-center/dgx-systems/',\n",
       " 'https://www.nvidia.com/en-us/data-center/products/certified-systems/',\n",
       " 'https://eventmobi.com/website/coreweave',\n",
       " 'https://eventmobi.com/website/coreweave',\n",
       " 'https://www.se.com/ww/en/about-us/newsroom/news/press-releases.jsp?id=68432d51b96642343f0f890b',\n",
       " 'https://www.se.com/ww/en/about-us/newsroom/news/press-releases.jsp?id=68432d51b96642343f0f890b',\n",
       " 'https://blogs.nvidia.com/blog/nvidia-deutsche-telekom-germany-sovereign-ai/',\n",
       " 'https://blogs.nvidia.com/blog/nvidia-deutsche-telekom-germany-sovereign-ai/',\n",
       " 'https://blogs.nvidia.com/blog/european-telcos-ai-factories/',\n",
       " 'https://blogs.nvidia.com/blog/european-telcos-ai-factories/',\n",
       " 'https://blogs.nvidia.com/blog/blackwell-performance-mlperf-training/',\n",
       " 'https://blogs.nvidia.com/blog/blackwell-performance-mlperf-training/',\n",
       " 'https://blogs.nvidia.com/blog/dell-technologies-ai-factories-blackwell/',\n",
       " 'https://blogs.nvidia.com/blog/dell-technologies-ai-factories-blackwell/',\n",
       " 'https://www.g42.ai/resources/news/global-tech-alliance-launches-stargate-uae',\n",
       " 'https://www.g42.ai/resources/news/global-tech-alliance-launches-stargate-uae',\n",
       " 'https://blogs.nvidia.com/blog/microsoft-build-agentic-ai-innovation-cloud-pc/',\n",
       " 'https://blogs.nvidia.com/blog/microsoft-build-agentic-ai-innovation-cloud-pc/',\n",
       " 'https://nvidianews.nvidia.com/news/nvidia-launches-ai-first-dgx-personal-computing-systems-with-global-computer-makers',\n",
       " 'https://nvidianews.nvidia.com/news/nvidia-launches-ai-first-dgx-personal-computing-systems-with-global-computer-makers',\n",
       " 'https://blogs.nvidia.com/blog/storage-leaders-ai-data-platform-agents',\n",
       " 'https://blogs.nvidia.com/blog/storage-leaders-ai-data-platform-agents',\n",
       " 'https://www.nvidia.com/en-us/about-nvidia/',\n",
       " 'https://www.nvidia.com/gtc/events/',\n",
       " 'https://www.nvidia.com/en-us/about-nvidia/careers/',\n",
       " 'https://nvidianews.nvidia.com',\n",
       " 'https://www.nvidia.com/en-us/on-demand',\n",
       " 'https://nvidianews.nvidia.com/bios',\n",
       " 'https://www.nvidia.com/content/dam/en-zz/Solutions/about-nvidia/corporate-nvidia-in-brief.pdf',\n",
       " 'https://images.nvidia.com/pdf/NVIDIA-Story.pdf',\n",
       " 'https://www.nvidia.com/en-eu/gtc/keynote/',\n",
       " 'https://www.nvidia.com/en-eu/gtc/keynote/',\n",
       " 'https://www.nvidia.com/en-us/on-demand/',\n",
       " 'https://www.nvidia.com/en-us/on-demand/',\n",
       " 'https://www.youtube.com/watch?v=TEGAQxg1gVA',\n",
       " 'https://www.youtube.com/watch?v=TEGAQxg1gVA',\n",
       " 'https://images.nvidia.com/aem-dam/Solutions/homepage/pdf/NVIDIA-Story.pdf',\n",
       " 'https://images.nvidia.com/aem-dam/Solutions/homepage/pdf/NVIDIA-Story.pdf',\n",
       " 'https://www.nvidia.com/en-us/about-nvidia/',\n",
       " 'https://www.nvidia.com/en-us/about-nvidia/',\n",
       " 'https://blogs.nvidia.com/blog/accelerated-ai-energy-efficiency/',\n",
       " 'https://blogs.nvidia.com/blog/accelerated-ai-energy-efficiency/',\n",
       " 'https://blogs.nvidia.com/blog/ai-data-science-career-development/',\n",
       " 'https://blogs.nvidia.com/blog/ai-data-science-career-development/',\n",
       " 'https://blogs.nvidia.com/blog/selin-ornek-robot-guide-dogs/',\n",
       " 'https://blogs.nvidia.com/blog/selin-ornek-robot-guide-dogs/',\n",
       " 'https://docs.nvidia.com/smlib/manual/smlib/index.html',\n",
       " 'https://docs.nvidia.com/smlib/manual/nlib/index.html',\n",
       " '#',\n",
       " 'https://docs.deci.ai/',\n",
       " '#',\n",
       " 'https://www.nvidia.com/en-us/about-nvidia/',\n",
       " 'https://images.nvidia.com/aem-dam/Solutions/homepage/pdf/NVIDIA-Story.pdf',\n",
       " 'https://investor.nvidia.com/home/default.aspx',\n",
       " 'https://www.nventures.ai',\n",
       " 'https://www.nvidia.com/en-us/foundation/',\n",
       " 'https://www.nvidia.com/en-us/research/',\n",
       " 'https://www.nvidia.com/en-us/sustainability/',\n",
       " 'https://www.nvidia.com/en-us/technologies/',\n",
       " 'https://www.nvidia.com/en-us/about-nvidia/careers/',\n",
       " 'https://nvidianews.nvidia.com/',\n",
       " 'https://blogs.nvidia.com/',\n",
       " 'https://developer.nvidia.com/blog/',\n",
       " 'https://www.nvidia.com/en-us/about-nvidia/webinar-portal/',\n",
       " 'https://www.nvidia.com/en-us/preferences/email-signup/',\n",
       " 'https://www.nvidia.com/en-us/events/',\n",
       " 'https://www.nvidia.com/gtc/events/',\n",
       " 'https://www.nvidia.com/en-us/on-demand/',\n",
       " 'https://developer.nvidia.com/',\n",
       " 'https://www.nvidia.com/en-us/about-nvidia/partners/',\n",
       " 'https://www.nvidia.com/en-us/executive-insights/',\n",
       " 'https://www.nvidia.com/en-us/startups/',\n",
       " 'https://www.nvidia.com/en-us/programs/isv/',\n",
       " 'https://docs.nvidia.com/',\n",
       " 'https://www.nvidia.com/en-us/training/',\n",
       " 'https://academy.nvidia.com/en/',\n",
       " 'https://www.nvidia.com/en-us/support/enterprise/advisory-services/',\n",
       " 'https://www.nvidia.com/en-us/preferences/email-signup/',\n",
       " 'https://www.facebook.com/NVIDIA',\n",
       " 'https://www.instagram.com/nvidia/?hl=en',\n",
       " 'https://www.linkedin.com/company/nvidia/',\n",
       " 'https://twitter.com/nvidia',\n",
       " 'https://www.youtube.com/user/nvidia',\n",
       " 'https://www.nvidia.com/en-us/location-selector/',\n",
       " 'https://www.nvidia.com/en-us/about-nvidia/privacy-policy/',\n",
       " 'https://www.nvidia.com/en-us/about-nvidia/privacy-center/',\n",
       " 'https://www.nvidia.com/en-us/preferences/email-preferences/',\n",
       " 'https://www.nvidia.com/en-us/about-nvidia/terms-of-service/',\n",
       " 'https://www.nvidia.com/en-us/about-nvidia/accessibility/',\n",
       " 'https://www.nvidia.com/en-us/about-nvidia/company-policies/',\n",
       " 'https://www.nvidia.com/en-us/product-security/',\n",
       " 'https://www.nvidia.com/en-us/contact/']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "websiteContent = Website(\"https://nvidia.com\")\n",
    "websiteContent.links"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1771af9c-717a-4fca-bbbe-8a95893312c3",
   "metadata": {},
   "source": [
    "## First step: Have GPT-4o-mini figure out which links are relevant\n",
    "\n",
    "### Use a call to gpt-4o-mini to read the links on a webpage, and respond in structured JSON.  \n",
    "It should decide which links are relevant, and replace relative links such as \"/about\" with \"https://company.com/about\".  \n",
    "We will use \"one shot prompting\" in which we provide an example of how it should respond in the prompt.\n",
    "\n",
    "This is an excellent use case for an LLM, because it requires nuanced understanding. Imagine trying to code this without LLMs by parsing and analyzing the webpage - it would be very hard!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6957b079-0d96-45f7-a26a-3487510e9b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "link_system_prompt = \"You are provided with a list of links found on a webpage. \\\n",
    "You are able to decide which of the links would be most relevant to include in a brochure about the company, \\\n",
    "such as links to an About page, or a Company page, or Careers/Jobs pages.\\n\"\n",
    "link_system_prompt += \"You should respond in JSON as in this example:\"\n",
    "link_system_prompt += \"\"\"\n",
    "{\n",
    "    \"links\": [\n",
    "        {\"type\": \"about page\", \"url\": \"https://full.url/goes/here/about\"},\n",
    "        {\"type\": \"careers page\": \"url\": \"https://another.full.url/careers\"}\n",
    "    ]\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b97e4068-97ed-4120-beae-c42105e4d59a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are provided with a list of links found on a webpage. You are able to decide which of the links would be most relevant to include in a brochure about the company, such as links to an About page, or a Company page, or Careers/Jobs pages.\n",
      "You should respond in JSON as in this example:\n",
      "{\n",
      "    \"links\": [\n",
      "        {\"type\": \"about page\", \"url\": \"https://full.url/goes/here/about\"},\n",
      "        {\"type\": \"careers page\": \"url\": \"https://another.full.url/careers\"}\n",
      "    ]\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(link_system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e1f601b-2eaf-499d-b6b8-c99050c9d6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links_user_prompt(website):\n",
    "    user_prompt = f\"Here is the list of links on the website of {website.url} - \"\n",
    "    user_prompt += \"please decide which of these are relevant web links for a brochure about the company, respond with the full https URL in JSON format. \\\n",
    "Do not include Terms of Service, Privacy, email links.\\n\"\n",
    "    user_prompt += \"Links (some might be relative links):\\n\"\n",
    "    user_prompt += \"\\n\".join(website.links)\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6bcbfa78-6395-4685-b92c-22d592050fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the list of links on the website of https://nvidia.com - please decide which of these are relevant web links for a brochure about the company, respond with the full https URL in JSON format. Do not include Terms of Service, Privacy, email links.\n",
      "Links (some might be relative links):\n",
      "https://www.nvidia.com\n",
      "#page-content\n",
      "https://www.nvidia.com/en-us/\n",
      "https://www.nvidia.com/en-us/clara/biopharma/\n",
      "https://www.nvidia.com/en-us/data-center/dgx-cloud/\n",
      "https://www.nvidia.com/en-us/gpu-cloud/nemo-llm-service/\n",
      "https://www.nvidia.com/en-us/omniverse/cloud/\n",
      "https://docs.nvidia.com/ngc/gpu-cloud/ngc-private-registry-user-guide/index.html\n",
      "https://www.nvidia.com/en-us/gpu-cloud/\n",
      "https://www.nvidia.com/en-us/data-center/\n",
      "https://www.nvidia.com/en-us/data-center/dgx-platform/\n",
      "https://www.nvidia.com/en-us/data-center/grace-cpu/\n",
      "https://www.nvidia.com/en-us/data-center/hgx/\n",
      "https://www.nvidia.com/en-us/edge-computing/products/igx/\n",
      "https://www.nvidia.com/en-us/data-center/products/mgx/\n",
      "https://www.nvidia.com/en-us/data-center/products/ovx/\n",
      "https://www.nvidia.com/en-us/autonomous-machines/embedded-systems/\n",
      "https://www.nvidia.com/en-us/solutions/autonomous-vehicles/in-vehicle-computing/\n",
      "https://www.nvidia.com/en-us/clara/medical-devices/\n",
      "https://www.nvidia.com/en-us/geforce/\n",
      "https://www.nvidia.com/en-us/geforce/graphics-cards/\n",
      "https://www.nvidia.com/en-us/geforce/laptops/\n",
      "https://www.nvidia.com/en-us/geforce/products/g-sync-monitors/\n",
      "https://www.nvidia.com/en-us/geforce/technologies/dlss/\n",
      "https://www.nvidia.com/en-us/geforce/technologies/reflex/\n",
      "https://www.nvidia.com/en-us/ai-on-rtx/\n",
      "https://www.nvidia.com/en-us/studio/laptops-desktops/\n",
      "https://www.nvidia.com/en-us/geforce-now/\n",
      "https://www.nvidia.com/en-us/software/nvidia-app/\n",
      "https://www.nvidia.com/en-us/geforce/broadcasting/\n",
      "https://www.nvidia.com/en-us/shield/\n",
      "https://www.nvidia.com/en-us/data-center/technologies/blackwell-architecture/\n",
      "https://www.nvidia.com/en-us/data-center/technologies/hopper-architecture/\n",
      "https://www.nvidia.com/en-us/technologies/ada-architecture/\n",
      "https://www.nvidia.com/en-us/geforce/graphics-cards/\n",
      "https://www.nvidia.com/en-us/products/workstations/\n",
      "https://www.nvidia.com/en-us/data-center/virtual-solutions/\n",
      "https://www.nvidia.com/en-us/geforce/laptops/\n",
      "https://www.nvidia.com/en-us/studio/laptops-desktops/\n",
      "https://www.nvidia.com/en-us/products/workstations/professional-laptops/\n",
      "https://www.nvidia.com/en-us/networking/\n",
      "https://www.nvidia.com/en-us/networking/products/data-processing-unit/\n",
      "https://www.nvidia.com/en-us/networking/products/ethernet/\n",
      "https://www.nvidia.com/en-us/networking/products/infiniband/\n",
      "https://www.nvidia.com/en-us/networking/products/software/\n",
      "https://www.nvidia.com/en-us/data-center/magnum-io/\n",
      "https://www.nvidia.com/en-us/products/workstations/\n",
      "https://www.nvidia.com/en-us/products/workstations/dgx-spark/\n",
      "https://www.nvidia.com/en-us/products/workstations/dgx-station/\n",
      "https://www.nvidia.com/en-us/products/workstations/ai-workstations/\n",
      "https://www.nvidia.com/en-us/products/workstations/professional-desktop-gpus/\n",
      "https://www.nvidia.com/en-us/products/workstations/professional-laptops/\n",
      "https://developer.nvidia.com/agentiq\n",
      "https://build.nvidia.com/blueprints\n",
      "https://www.nvidia.com/en-us/ai/dynamo/\n",
      "https://www.nvidia.com/en-us/ai-data-science/products/nim-microservices/\n",
      "https://www.nvidia.com/en-us/technologies/cuda-x/\n",
      "https://www.nvidia.com/en-us/self-driving-cars/in-vehicle-computing/\n",
      "https://developer.nvidia.com/ace/tokkio-showcase\n",
      "https://developer.nvidia.com/MAXINE\n",
      "https://www.nvidia.com/en-us/ai-data-science/products/morpheus/\n",
      "https://www.nvidia.com/en-us/deep-learning-ai/solutions/data-science/apache-spark-3/\n",
      "https://developer.nvidia.com/rapids/\n",
      "https://www.nvidia.com/en-us/ai-data-science/products/cuopt/\n",
      "https://www.nvidia.com/en-us/ai-data-science/products/nemo/\n",
      "https://www.nvidia.com/en-us/clara/\n",
      "https://www.nvidia.com/en-us/omniverse/\n",
      "https://www.nvidia.com/en-us/autonomous-machines/intelligent-video-analytics-platform/\n",
      "https://www.nvidia.com/en-us/data-center/mission-control/\n",
      "https://www.nvidia.com/en-us/data-center/products/ai-enterprise/\n",
      "https://www.nvidia.com/en-us/ai/cosmos/\n",
      "https://www.nvidia.com/en-us/software/run-ai/\n",
      "https://developer.nvidia.com/isaac/ros\n",
      "https://developer.nvidia.com/aerial\n",
      "https://www.nvidia.com/en-us/software/\n",
      "https://www.nvidia.com/en-us/deep-learning-ai/solutions/data-science/workbench/\n",
      "https://build.nvidia.com/explore/discover\n",
      "https://www.nvidia.com/en-us/data-center/enterprise-software/\n",
      "https://developer.nvidia.com/dcgm\n",
      "https://developer.nvidia.com/tools-overview\n",
      "https://catalog.ngc.nvidia.com/\n",
      "https://www.nvidia.com/en-us/software/nvidia-app-enterprise/\n",
      "https://www.nvidia.com/en-us/gpu-cloud/\n",
      "https://www.nvidia.com/en-us/software/rtx-desktop-manager/\n",
      "https://www.nvidia.com/en-us/studio/software/\n",
      "https://www.nvidia.com/en-us/design-visualization/software/broadcast-app/\n",
      "https://www.nvidia.com/en-us/solutions/ai/\n",
      "https://www.nvidia.com/en-us/ai/\n",
      "https://www.nvidia.com/en-us/data-center/ai-data-platform/\n",
      "https://www.nvidia.com/en-us/solutions/ai/conversational-ai/\n",
      "https://www.nvidia.com/en-us/solutions/ai/cybersecurity/\n",
      "https://www.nvidia.com/en-us/deep-learning-ai/solutions/data-science/\n",
      "https://www.nvidia.com/en-us/solutions/ai/generative-ai/\n",
      "https://www.nvidia.com/en-us/solutions/ai/inference/\n",
      "https://www.nvidia.com/en-us/data-center/\n",
      "https://www.nvidia.com/en-us/data-center/ai-data-platform/\n",
      "https://www.nvidia.com/en-us/data-center/solutions/accelerated-computing/\n",
      "https://www.nvidia.com/en-us/data-center/gpu-cloud-computing/\n",
      "https://www.nvidia.com/en-us/data-center/colocation-partners/\n",
      "https://www.nvidia.com/en-us/data-center/solutions/mlops/\n",
      "https://www.nvidia.com/en-us/networking/\n",
      "https://www.nvidia.com/en-us/data-center/sustainable-computing/\n",
      "https://www.nvidia.com/en-us/data-center/virtual-solutions/\n",
      "https://www.nvidia.com/en-us/solutions/design-and-simulation/\n",
      "https://www.nvidia.com/en-us/solutions/cae/\n",
      "https://www.nvidia.com/en-us/glossary/digital-twin/\n",
      "https://www.nvidia.com/en-us/solutions/rendering/\n",
      "https://www.nvidia.com/en-us/solutions/robotics-and-edge-computing/\n",
      "https://www.nvidia.com/en-us/high-performance-computing/scientific-visualization/\n",
      "https://www.nvidia.com/en-us/solutions/autonomous-vehicles/\n",
      "https://www.nvidia.com/en-us/design-visualization/solutions/virtual-reality/\n",
      "https://www.nvidia.com/en-us/high-performance-computing/\n",
      "https://www.nvidia.com/en-us/high-performance-computing/hpc-and-ai/\n",
      "https://www.nvidia.com/en-us/high-performance-computing/scientific-visualization/\n",
      "https://www.nvidia.com/en-us/high-performance-computing/simulation-and-modeling/\n",
      "https://www.nvidia.com/en-us/solutions/quantum-computing/\n",
      "https://www.nvidia.com/en-us/solutions/robotics-and-edge-computing/\n",
      "https://www.nvidia.com/en-us/industries/robotics/\n",
      "https://www.nvidia.com/en-us/edge-computing/\n",
      "https://www.nvidia.com/en-us/autonomous-machines/intelligent-video-analytics-platform/\n",
      "https://www.nvidia.com/en-us/solutions/autonomous-vehicles/\n",
      "https://www.nvidia.com/en-us/solutions/autonomous-vehicles/ai-training/\n",
      "https://www.nvidia.com/en-us/use-cases/autonomous-vehicle-simulation/\n",
      "https://www.nvidia.com/en-us/solutions/autonomous-vehicles/in-vehicle-computing/\n",
      "https://www.nvidia.com/en-us/solutions/autonomous-vehicles/safety/\n",
      "https://www.nvidia.com/en-us/industries/\n",
      "https://www.nvidia.com/en-us/industries/aec/\n",
      "https://www.nvidia.com/en-us/industries/automotive/\n",
      "https://www.nvidia.com/en-us/industries/consumer-internet/\n",
      "https://www.nvidia.com/en-us/solutions/ai/cybersecurity/\n",
      "https://www.nvidia.com/en-us/industries/energy/\n",
      "https://www.nvidia.com/en-us/industries/finance/\n",
      "https://www.nvidia.com/en-us/industries/healthcare-life-sciences/\n",
      "https://www.nvidia.com/en-us/industries/higher-education-research/\n",
      "https://www.nvidia.com/en-us/industries/game-development/\n",
      "https://www.nvidia.com/en-us/industries/global-public-sector/\n",
      "https://www.nvidia.com/en-us/industries/manufacturing/\n",
      "https://www.nvidia.com/en-us/industries/media-and-entertainment/\n",
      "https://www.nvidia.com/en-us/industries/public-sector/\n",
      "https://www.nvidia.com/en-us/industries/restaurants/\n",
      "https://www.nvidia.com/en-us/industries/retail/\n",
      "https://www.nvidia.com/en-us/industries/robotics/\n",
      "https://www.nvidia.com/en-us/industries/smart-cities-and-spaces/\n",
      "https://www.nvidia.com/en-us/industries/supercomputing/\n",
      "https://www.nvidia.com/en-us/industries/telecommunications/\n",
      "https://www.nvidia.com/en-us/industries/transportation/\n",
      "https://marketplace.nvidia.com/en-us/\n",
      "https://www.nvidia.com/en-us/drivers/\n",
      "https://www.nvidia.com/en-us/support/\n",
      "#\n",
      "#\n",
      "#\n",
      "https://www.nvidia.com/en-us/account/\n",
      "#\n",
      "#\n",
      "#page-content\n",
      "#\n",
      "#\n",
      "https://www.nvidia.com/en-us/\n",
      "/\n",
      "#\n",
      "https://www.nvidia.com/en-us/account/\n",
      "#\n",
      "#\n",
      "https://www.nvidia.com/en-us/clara/biopharma/\n",
      "https://www.nvidia.com/en-us/data-center/dgx-cloud/\n",
      "https://www.nvidia.com/en-us/gpu-cloud/nemo-llm-service/\n",
      "https://www.nvidia.com/en-us/omniverse/cloud/\n",
      "https://docs.nvidia.com/ngc/gpu-cloud/ngc-private-registry-user-guide/index.html\n",
      "https://www.nvidia.com/en-us/gpu-cloud/\n",
      "https://www.nvidia.com/en-us/data-center/\n",
      "https://www.nvidia.com/en-us/data-center/dgx-platform/\n",
      "https://www.nvidia.com/en-us/data-center/grace-cpu/\n",
      "https://www.nvidia.com/en-us/data-center/hgx/\n",
      "https://www.nvidia.com/en-us/edge-computing/products/igx/\n",
      "https://www.nvidia.com/en-us/data-center/products/mgx/\n",
      "https://www.nvidia.com/en-us/data-center/products/ovx/\n",
      "https://www.nvidia.com/en-us/autonomous-machines/embedded-systems/\n",
      "https://www.nvidia.com/en-us/solutions/autonomous-vehicles/in-vehicle-computing/\n",
      "https://www.nvidia.com/en-us/clara/medical-devices/\n",
      "https://www.nvidia.com/en-us/geforce/\n",
      "https://www.nvidia.com/en-us/geforce/graphics-cards/\n",
      "https://www.nvidia.com/en-us/geforce/laptops/\n",
      "https://www.nvidia.com/en-us/geforce/products/g-sync-monitors/\n",
      "https://www.nvidia.com/en-us/geforce/technologies/dlss/\n",
      "https://www.nvidia.com/en-us/geforce/technologies/reflex/\n",
      "https://www.nvidia.com/en-us/ai-on-rtx/\n",
      "https://www.nvidia.com/en-us/studio/laptops-desktops/\n",
      "https://www.nvidia.com/en-us/geforce-now/\n",
      "https://www.nvidia.com/en-us/software/nvidia-app/\n",
      "https://www.nvidia.com/en-us/geforce/broadcasting/\n",
      "https://www.nvidia.com/en-us/shield/\n",
      "https://www.nvidia.com/en-us/data-center/technologies/blackwell-architecture/\n",
      "https://www.nvidia.com/en-us/data-center/technologies/hopper-architecture/\n",
      "https://www.nvidia.com/en-us/technologies/ada-architecture/\n",
      "https://www.nvidia.com/en-us/geforce/graphics-cards/\n",
      "https://www.nvidia.com/en-us/products/workstations/\n",
      "https://www.nvidia.com/en-us/data-center/virtual-solutions/\n",
      "https://www.nvidia.com/en-us/geforce/laptops/\n",
      "https://www.nvidia.com/en-us/studio/laptops-desktops/\n",
      "https://www.nvidia.com/en-us/products/workstations/professional-laptops/\n",
      "https://www.nvidia.com/en-us/networking/\n",
      "https://www.nvidia.com/en-us/networking/products/data-processing-unit/\n",
      "https://www.nvidia.com/en-us/networking/products/ethernet/\n",
      "https://www.nvidia.com/en-us/networking/products/infiniband/\n",
      "https://www.nvidia.com/en-us/networking/products/software/\n",
      "https://www.nvidia.com/en-us/data-center/magnum-io/\n",
      "https://www.nvidia.com/en-us/products/workstations/\n",
      "https://www.nvidia.com/en-us/products/workstations/dgx-spark/\n",
      "https://www.nvidia.com/en-us/products/workstations/dgx-station/\n",
      "https://www.nvidia.com/en-us/products/workstations/ai-workstations/\n",
      "https://www.nvidia.com/en-us/products/workstations/professional-desktop-gpus/\n",
      "https://www.nvidia.com/en-us/products/workstations/professional-laptops/\n",
      "https://developer.nvidia.com/agentiq\n",
      "https://build.nvidia.com/blueprints\n",
      "https://www.nvidia.com/en-us/ai/dynamo/\n",
      "https://www.nvidia.com/en-us/ai-data-science/products/nim-microservices/\n",
      "https://www.nvidia.com/en-us/technologies/cuda-x/\n",
      "https://www.nvidia.com/en-us/self-driving-cars/in-vehicle-computing/\n",
      "https://developer.nvidia.com/ace/tokkio-showcase\n",
      "https://developer.nvidia.com/MAXINE\n",
      "https://www.nvidia.com/en-us/ai-data-science/products/morpheus/\n",
      "https://www.nvidia.com/en-us/deep-learning-ai/solutions/data-science/apache-spark-3/\n",
      "https://developer.nvidia.com/rapids/\n",
      "https://www.nvidia.com/en-us/ai-data-science/products/cuopt/\n",
      "https://www.nvidia.com/en-us/ai-data-science/products/nemo/\n",
      "https://www.nvidia.com/en-us/clara/\n",
      "https://www.nvidia.com/en-us/omniverse/\n",
      "https://www.nvidia.com/en-us/autonomous-machines/intelligent-video-analytics-platform/\n",
      "https://www.nvidia.com/en-us/data-center/mission-control/\n",
      "https://www.nvidia.com/en-us/data-center/products/ai-enterprise/\n",
      "https://www.nvidia.com/en-us/ai/cosmos/\n",
      "https://www.nvidia.com/en-us/software/run-ai/\n",
      "https://developer.nvidia.com/isaac/ros\n",
      "https://developer.nvidia.com/aerial\n",
      "https://www.nvidia.com/en-us/software/\n",
      "https://www.nvidia.com/en-us/deep-learning-ai/solutions/data-science/workbench/\n",
      "https://build.nvidia.com/explore/discover\n",
      "https://www.nvidia.com/en-us/data-center/enterprise-software/\n",
      "https://developer.nvidia.com/dcgm\n",
      "https://developer.nvidia.com/tools-overview\n",
      "https://catalog.ngc.nvidia.com/\n",
      "https://www.nvidia.com/en-us/software/nvidia-app-enterprise/\n",
      "https://www.nvidia.com/en-us/gpu-cloud/\n",
      "https://www.nvidia.com/en-us/software/rtx-desktop-manager/\n",
      "https://www.nvidia.com/en-us/studio/software/\n",
      "https://www.nvidia.com/en-us/design-visualization/software/broadcast-app/\n",
      "https://www.nvidia.com/en-us/solutions/ai/\n",
      "https://www.nvidia.com/en-us/ai/\n",
      "https://www.nvidia.com/en-us/data-center/ai-data-platform/\n",
      "https://www.nvidia.com/en-us/solutions/ai/conversational-ai/\n",
      "https://www.nvidia.com/en-us/solutions/ai/cybersecurity/\n",
      "https://www.nvidia.com/en-us/deep-learning-ai/solutions/data-science/\n",
      "https://www.nvidia.com/en-us/solutions/ai/generative-ai/\n",
      "https://www.nvidia.com/en-us/solutions/ai/inference/\n",
      "https://www.nvidia.com/en-us/data-center/\n",
      "https://www.nvidia.com/en-us/data-center/ai-data-platform/\n",
      "https://www.nvidia.com/en-us/data-center/solutions/accelerated-computing/\n",
      "https://www.nvidia.com/en-us/data-center/gpu-cloud-computing/\n",
      "https://www.nvidia.com/en-us/data-center/colocation-partners/\n",
      "https://www.nvidia.com/en-us/data-center/solutions/mlops/\n",
      "https://www.nvidia.com/en-us/networking/\n",
      "https://www.nvidia.com/en-us/data-center/sustainable-computing/\n",
      "https://www.nvidia.com/en-us/data-center/virtual-solutions/\n",
      "https://www.nvidia.com/en-us/solutions/design-and-simulation/\n",
      "https://www.nvidia.com/en-us/solutions/cae/\n",
      "https://www.nvidia.com/en-us/glossary/digital-twin/\n",
      "https://www.nvidia.com/en-us/solutions/rendering/\n",
      "https://www.nvidia.com/en-us/solutions/robotics-and-edge-computing/\n",
      "https://www.nvidia.com/en-us/high-performance-computing/scientific-visualization/\n",
      "https://www.nvidia.com/en-us/solutions/autonomous-vehicles/\n",
      "https://www.nvidia.com/en-us/design-visualization/solutions/virtual-reality/\n",
      "https://www.nvidia.com/en-us/high-performance-computing/\n",
      "https://www.nvidia.com/en-us/high-performance-computing/hpc-and-ai/\n",
      "https://www.nvidia.com/en-us/high-performance-computing/scientific-visualization/\n",
      "https://www.nvidia.com/en-us/high-performance-computing/simulation-and-modeling/\n",
      "https://www.nvidia.com/en-us/solutions/quantum-computing/\n",
      "https://www.nvidia.com/en-us/solutions/robotics-and-edge-computing/\n",
      "https://www.nvidia.com/en-us/industries/robotics/\n",
      "https://www.nvidia.com/en-us/edge-computing/\n",
      "https://www.nvidia.com/en-us/autonomous-machines/intelligent-video-analytics-platform/\n",
      "https://www.nvidia.com/en-us/solutions/autonomous-vehicles/\n",
      "https://www.nvidia.com/en-us/solutions/autonomous-vehicles/ai-training/\n",
      "https://www.nvidia.com/en-us/use-cases/autonomous-vehicle-simulation/\n",
      "https://www.nvidia.com/en-us/solutions/autonomous-vehicles/in-vehicle-computing/\n",
      "https://www.nvidia.com/en-us/solutions/autonomous-vehicles/safety/\n",
      "https://www.nvidia.com/en-us/industries/\n",
      "https://www.nvidia.com/en-us/industries/aec/\n",
      "https://www.nvidia.com/en-us/industries/automotive/\n",
      "https://www.nvidia.com/en-us/industries/consumer-internet/\n",
      "https://www.nvidia.com/en-us/solutions/ai/cybersecurity/\n",
      "https://www.nvidia.com/en-us/industries/energy/\n",
      "https://www.nvidia.com/en-us/industries/finance/\n",
      "https://www.nvidia.com/en-us/industries/healthcare-life-sciences/\n",
      "https://www.nvidia.com/en-us/industries/higher-education-research/\n",
      "https://www.nvidia.com/en-us/industries/game-development/\n",
      "https://www.nvidia.com/en-us/industries/global-public-sector/\n",
      "https://www.nvidia.com/en-us/industries/manufacturing/\n",
      "https://www.nvidia.com/en-us/industries/media-and-entertainment/\n",
      "https://www.nvidia.com/en-us/industries/public-sector/\n",
      "https://www.nvidia.com/en-us/industries/restaurants/\n",
      "https://www.nvidia.com/en-us/industries/retail/\n",
      "https://www.nvidia.com/en-us/industries/robotics/\n",
      "https://www.nvidia.com/en-us/industries/smart-cities-and-spaces/\n",
      "https://www.nvidia.com/en-us/industries/supercomputing/\n",
      "https://www.nvidia.com/en-us/industries/telecommunications/\n",
      "https://www.nvidia.com/en-us/industries/transportation/\n",
      "https://marketplace.nvidia.com/en-us/\n",
      "https://www.nvidia.com/en-us/drivers/\n",
      "https://www.nvidia.com/en-us/support/\n",
      "http://www.enable-javascript.com/\n",
      "https://blogs.nvidia.com/blog/hpe-nvidia-ai-factory\n",
      "https://eventmobi.com/website/coreweave\n",
      "https://www.nvidia.com/en-eu/gtc/keynote/\n",
      "https://blogs.nvidia.com/blog/auto-research-cvpr-2025/\n",
      "https://nvidianews.nvidia.com/news/europe-ai-infrastructure\n",
      "https://nvidianews.nvidia.com/news/nvidia-partners-with-europe-model-builders-and-cloud-providers-to-accelerate-regions-leap-into-ai\n",
      "https://www.nvidia.com/en-eu/gtc/keynote/\n",
      "https://www.nvidia.com/en-us/ai-data-science/\n",
      "https://www.nvidia.com/en-us/deep-learning-ai/solutions/data-analytics/\n",
      "https://www.nvidia.com/en-us/deep-learning-ai/solutions/machine-learning/\n",
      "https://www.nvidia.com/en-us/deep-learning-ai/solutions/prediction-forecasting/\n",
      "https://developer.nvidia.com/nvidia-merlin\n",
      "https://www.nvidia.com/en-us/ai-data-science/products/riva/\n",
      "https://www.nvidia.com/en-us/deep-learning-ai/solutions/data-science/apache-spark-3/\n",
      "https://www.nvidia.com/en-us/deep-learning-ai/software/rapids/\n",
      "https://www.nvidia.com/en-us/case-studies/shell-trains-custom-ai-chatbot-with-nemo/\n",
      "https://www.nvidia.com/en-us/case-studies/shell-trains-custom-ai-chatbot-with-nemo/\n",
      "https://www.nvidia.com/en-us/case-studies/linker-vision-ai-smart-city-solutions/\n",
      "https://www.nvidia.com/en-us/case-studies/linker-vision-ai-smart-city-solutions/\n",
      "https://blogs.nvidia.com/blog/europe-6g-research/\n",
      "https://blogs.nvidia.com/blog/europe-6g-research/\n",
      "https://blogs.nvidia.com/blog/france-sovereign-ai-infrastructure/\n",
      "https://blogs.nvidia.com/blog/france-sovereign-ai-infrastructure/\n",
      "https://blogs.nvidia.com/blog/sovereign-ai-agents-factories/\n",
      "https://blogs.nvidia.com/blog/sovereign-ai-agents-factories/\n",
      "https://blogs.nvidia.com/blog/europe-financial-services-ai/\n",
      "https://blogs.nvidia.com/blog/europe-financial-services-ai/\n",
      "https://blogs.nvidia.com/blog/european-broadcasting-union-sovereign-ai/\n",
      "https://blogs.nvidia.com/blog/european-broadcasting-union-sovereign-ai/\n",
      "https://blogs.nvidia.com/blog/retail-agentic-physical-ai/\n",
      "https://blogs.nvidia.com/blog/retail-agentic-physical-ai/\n",
      "https://blogs.nvidia.com/blog/ai-blueprint-telco-network-configuration/\n",
      "https://blogs.nvidia.com/blog/ai-blueprint-telco-network-configuration/\n",
      "https://blogs.nvidia.com/blog/rtx-ai-garage-fity-flex-flux-comfyui-stable-diffusion\n",
      "https://blogs.nvidia.com/blog/rtx-ai-garage-fity-flex-flux-comfyui-stable-diffusion\n",
      "https://store.nvidia.com/en-us/nvidia-rtx/store/?page=1&limit=9&locale=en-us\n",
      "https://blogs.nvidia.com/blog/category/pro-graphics/\n",
      "https://www.nvidia.com/en-us/design-visualization/\n",
      "https://www.nvidia.com/en-us/omniverse/\n",
      "https://developer.nvidia.com/rtx\n",
      "https://www.nvidia.com/en-us/research/\n",
      "https://www.nvidia.com/en-us/design-visualization/solutions/cloud-xr/\n",
      "https://blogs.nvidia.com/blog/wfm-advance-av-sim-safety/\n",
      "https://blogs.nvidia.com/blog/wfm-advance-av-sim-safety/\n",
      "https://blogs.nvidia.com/blog/smart-city-ai-blueprint-europe\n",
      "https://blogs.nvidia.com/blog/smart-city-ai-blueprint-europe\n",
      "https://blogs.nvidia.com/blog/omniverse-digital-twins-taiwan-manufacturers-physical-ai\n",
      "https://blogs.nvidia.com/blog/omniverse-digital-twins-taiwan-manufacturers-physical-ai\n",
      "https://blogs.nvidia.com/blog/omniverse-blueprint-ai-factories-expands\n",
      "https://blogs.nvidia.com/blog/omniverse-blueprint-ai-factories-expands\n",
      "https://blogs.nvidia.com/blog/computational-fluid-dynamics-digital-twins/\n",
      "https://blogs.nvidia.com/blog/computational-fluid-dynamics-digital-twins/\n",
      "https://blogs.nvidia.com/blog/how-digital-twins-scale-industrial-ai\n",
      "https://blogs.nvidia.com/blog/how-digital-twins-scale-industrial-ai\n",
      "https://blogs.nvidia.com/blog/mega-omniverse-blueprint-industrial-digital-twins\n",
      "https://blogs.nvidia.com/blog/mega-omniverse-blueprint-industrial-digital-twins\n",
      "https://nvidianews.nvidia.com/news/nvidia-announces-major-release-of-cosmos-world-foundation-models-and-physical-ai-data-tools\n",
      "https://nvidianews.nvidia.com/news/nvidia-announces-major-release-of-cosmos-world-foundation-models-and-physical-ai-data-tools\n",
      "https://nvidianews.nvidia.com/news/nvidia-omniverse-physical-ai-operating-system-expands-to-more-industries-and-partners\n",
      "https://nvidianews.nvidia.com/news/nvidia-omniverse-physical-ai-operating-system-expands-to-more-industries-and-partners\n",
      "https://blogs.nvidia.com/blog/omniverse-blueprint-ai-factory/\n",
      "https://blogs.nvidia.com/blog/omniverse-blueprint-ai-factory/\n",
      "https://www.nvidia.com/en-us/high-performance-computing/\n",
      "https://www.nvidia.com/en-us/events/supercomputing/\n",
      "https://www.nvidia.com/en-us/lp/high-performance-computing/hpc-ai-cloud-computing-ebook/\n",
      "https://www.nvidia.com/en-us/industries/healthcare-life-sciences/\n",
      "https://www.nvidia.com/en-us/industries/public-sector/\n",
      "https://www.nvidia.com/en-us/industries/energy/\n",
      "https://developer.nvidia.com/hpc-sdk\n",
      "https://developer.nvidia.com/physicsnemo\n",
      "https://blogs.nvidia.com/blog/ansys-dcai-quantum-computing/\n",
      "https://blogs.nvidia.com/blog/ansys-dcai-quantum-computing/\n",
      "https://blogs.nvidia.com/blog/journey-to-quantum-computing/\n",
      "https://blogs.nvidia.com/blog/journey-to-quantum-computing/\n",
      "https://nvidianews.nvidia.com/news/nvidia-powers-europes-fastest-supercomputer\n",
      "https://nvidianews.nvidia.com/news/nvidia-powers-europes-fastest-supercomputer\n",
      "http://blogs.nvidia.com/blog/blue-lion-vera-rubin\n",
      "http://blogs.nvidia.com/blog/blue-lion-vera-rubin\n",
      "https://blogs.nvidia.com/blog/earth2-generative-ai-foundation-model-global-climate-kilometer-scale-resolution\n",
      "https://blogs.nvidia.com/blog/earth2-generative-ai-foundation-model-global-climate-kilometer-scale-resolution\n",
      "https://blogs.nvidia.com/blog/dell-nvidia-berkeley-doudna/\n",
      "https://blogs.nvidia.com/blog/dell-nvidia-berkeley-doudna/\n",
      "https://nvidianews.nvidia.com/news/nvidia-powers-worlds-largest-quantum-research-supercomputer\n",
      "https://nvidianews.nvidia.com/news/nvidia-powers-worlds-largest-quantum-research-supercomputer\n",
      "https://blogs.nvidia.com/blog/semiconductor-industry-electronic-design-automation-blackwell-cuda-x\n",
      "https://blogs.nvidia.com/blog/semiconductor-industry-electronic-design-automation-blackwell-cuda-x\n",
      "https://nvidianews.nvidia.com/news/nvidia-to-build-accelerated-quantum-computing-research-center\n",
      "https://nvidianews.nvidia.com/news/nvidia-to-build-accelerated-quantum-computing-research-center\n",
      "https://nvidianews.nvidia.com/news/nvidia-and-ge-healthcare-collaborate-to-advance-the-development-of-autonomous-diagnostic-imaging-with-physical-ai\n",
      "https://nvidianews.nvidia.com/news/nvidia-and-ge-healthcare-collaborate-to-advance-the-development-of-autonomous-diagnostic-imaging-with-physical-ai\n",
      "https://store.nvidia.com/en-us/geforce/store/?page=1&limit=9&locale=en-us\n",
      "https://www.nvidia.com/en-us/geforce/\n",
      "https://www.nvidia.com/en-us/geforce/graphics-cards/\n",
      "https://www.nvidia.com/en-us/geforce/gaming-laptops/\n",
      "https://www.nvidia.com/en-us/geforce/technologies/dlss/\n",
      "https://www.nvidia.com/en-us/geforce/technologies/reflex/\n",
      "https://www.nvidia.com/en-us/studio/\n",
      "https://www.nvidia.com/en-us/geforce-now/\n",
      "https://www.nvidia.com/en-us/software/nvidia-app/\n",
      "https://www.nvidia.com/en-us/geforce/game-ready-drivers/\n",
      "https://www.nvidia.com/en-us/geforce/products/g-sync-monitors/\n",
      "https://www.nvidia.com/en-us/geforce/news/rtx-5060-out-now/\n",
      "https://www.nvidia.com/en-us/geforce/news/rtx-5060-out-now/\n",
      "https://www.nvidia.com/en-us/geforce/news/doom-the-dark-ages-path-tracing-dlss-ray-reconstruction-update/\n",
      "https://www.nvidia.com/en-us/geforce/news/doom-the-dark-ages-path-tracing-dlss-ray-reconstruction-update/\n",
      "https://www.nvidia.com/en-us/geforce/news/diablo-iv-strinova-eternal-strands-dlss-4-multi-frame-gen/\n",
      "https://www.nvidia.com/en-us/geforce/news/diablo-iv-strinova-eternal-strands-dlss-4-multi-frame-gen/\n",
      "https://www.nvidia.com/en-us/geforce/news/dune-awakening-dlss-4-multi-frame-generation-out-now/\n",
      "https://www.nvidia.com/en-us/geforce/news/dune-awakening-dlss-4-multi-frame-generation-out-now/\n",
      "https://www.nvidia.com/en-us/geforce/news/125-dlss-4-multi-frame-gen-games-more-announced-computex-2025/\n",
      "https://www.nvidia.com/en-us/geforce/news/125-dlss-4-multi-frame-gen-games-more-announced-computex-2025/\n",
      "https://www.nvidia.com/en-us/geforce/news/rtx-remix-mod-contest-portal-with-rtx-dlss-4-multi-frame-gen/\n",
      "https://www.nvidia.com/en-us/geforce/news/rtx-remix-mod-contest-portal-with-rtx-dlss-4-multi-frame-gen/\n",
      "https://www.nvidia.com/en-us/geforce/news/g-assist-ai-companion-for-rtx-ai-pcs/\n",
      "https://www.nvidia.com/en-us/geforce/news/g-assist-ai-companion-for-rtx-ai-pcs/\n",
      "https://www.nvidia.com/en-us/geforce/news/reflex-available-now-in-over-150-games/\n",
      "https://www.nvidia.com/en-us/geforce/news/reflex-available-now-in-over-150-games/\n",
      "https://blogs.nvidia.com/blog/geforce-now-thursday-elder-scrolls-online-member-reward\n",
      "https://blogs.nvidia.com/blog/geforce-now-thursday-elder-scrolls-online-member-reward\n",
      "https://blogs.nvidia.com/blog/rtx-ai-garage-g-assist-hackathon-plug-in\n",
      "https://blogs.nvidia.com/blog/rtx-ai-garage-g-assist-hackathon-plug-in\n",
      "https://www.nvidia.com/en-us/industries/automotive/\n",
      "https://www.nvidia.com/en-us/self-driving-cars/\n",
      "https://www.nvidia.com/en-us/self-driving-cars/in-vehicle-computing/\n",
      "https://www.nvidia.com/en-us/self-driving-cars/ai-training/\n",
      "https://www.nvidia.com/en-us/use-cases/autonomous-vehicle-simulation/\n",
      "https://blogs.nvidia.com/blog/tag/av-podcast/\n",
      "https://www.nvidia.com/en-us/self-driving-cars/drive-videos/\n",
      "https://blogs.nvidia.com/blog/auto-research-cvpr-2025/\n",
      "https://blogs.nvidia.com/blog/auto-research-cvpr-2025/\n",
      "https://nvidianews.nvidia.com/news/general-motors-and-nvidia-collaborate-on-ai-for-next-generation-vehicle-experience-and-manufacturing\n",
      "https://nvidianews.nvidia.com/news/general-motors-and-nvidia-collaborate-on-ai-for-next-generation-vehicle-experience-and-manufacturing\n",
      "https://blogs.nvidia.com/blog/halos-safety-system-autonomous-vehicles/\n",
      "https://blogs.nvidia.com/blog/halos-safety-system-autonomous-vehicles/\n",
      "https://blogs.nvidia.com/blog/auto-ecosystem-physical-ai/\n",
      "https://blogs.nvidia.com/blog/auto-ecosystem-physical-ai/\n",
      "https://blogs.nvidia.com/blog/drive-partners-showcase-ces/\n",
      "https://blogs.nvidia.com/blog/drive-partners-showcase-ces/\n",
      "https://nvidianews.nvidia.com/news/nvidia-launches-cosmos-world-foundation-model-platform-to-accelerate-physical-ai-development\n",
      "https://nvidianews.nvidia.com/news/nvidia-launches-cosmos-world-foundation-model-platform-to-accelerate-physical-ai-development\n",
      "https://blogs.nvidia.com/blog/hyundai-motor-group-ces/\n",
      "https://blogs.nvidia.com/blog/hyundai-motor-group-ces/\n",
      "https://nvidianews.nvidia.com/news/toyota-aurora-continental-nvidia-drive\n",
      "https://nvidianews.nvidia.com/news/toyota-aurora-continental-nvidia-drive\n",
      "https://blogs.nvidia.com/blog/three-computer-cosmos-ces/\n",
      "https://blogs.nvidia.com/blog/three-computer-cosmos-ces/\n",
      "https://blogs.nvidia.com/blog/drive-ai-lab-ces/\n",
      "https://blogs.nvidia.com/blog/drive-ai-lab-ces/\n",
      "https://store.nvidia.com/en-us/jetson/store/?page=1&limit=9&locale=en-us\n",
      "https://www.nvidia.com/en-us/edge-computing/\n",
      "https://developer.nvidia.com/isaac\n",
      "https://www.nvidia.com/en-us/autonomous-machines/\n",
      "https://www.nvidia.com/en-us/research/robotics/\n",
      "https://www.nvidia.com/en-us/autonomous-machines/\n",
      "https://www.nvidia.com/en-us/edge-computing/products/igx/\n",
      "https://www.nvidia.com/en-us/data-center/products/certified-systems/\n",
      "https://developer.nvidia.com/embedded/ecosystem\n",
      "https://blogs.nvidia.com/blog/hexagon-robotics-ai-software-aeon-humanoid\n",
      "https://blogs.nvidia.com/blog/hexagon-robotics-ai-software-aeon-humanoid\n",
      "https://blogs.nvidia.com/blog/european-robot-makers-isaac-omniverse-halos-safe-physical-ai\n",
      "https://blogs.nvidia.com/blog/european-robot-makers-isaac-omniverse-halos-safe-physical-ai\n",
      "https://blogs.nvidia.com/blog/foxconn-smart-hospital-robot/\n",
      "https://blogs.nvidia.com/blog/foxconn-smart-hospital-robot/\n",
      "https://developer.nvidia.com/blog/r2d2-unlocking-robotic-assembly-and-contact-rich-manipulation-with-nvidia-research/\n",
      "https://developer.nvidia.com/blog/r2d2-unlocking-robotic-assembly-and-contact-rich-manipulation-with-nvidia-research/\n",
      "https://blogs.nvidia.com/blog/nvidia-research-robotics-icra-2025/\n",
      "https://blogs.nvidia.com/blog/nvidia-research-robotics-icra-2025/\n",
      "https://nvidianews.nvidia.com/news/nvidia-powers-humanoid-robot-industry-with-cloud-to-robot-computing-platforms-for-physical-ai\n",
      "https://nvidianews.nvidia.com/news/nvidia-powers-humanoid-robot-industry-with-cloud-to-robot-computing-platforms-for-physical-ai\n",
      "https://developer.nvidia.com/blog/r%c2%b2d%c2%b2-adapting-dexterous-robots-with-nvidia-research-workflows-and-models/\n",
      "https://developer.nvidia.com/blog/r%c2%b2d%c2%b2-adapting-dexterous-robots-with-nvidia-research-workflows-and-models/\n",
      "https://blogs.nvidia.com/blog/national-robotics-week-2025/\n",
      "https://blogs.nvidia.com/blog/national-robotics-week-2025/\n",
      "https://developer.nvidia.com/blog/r2d2-advancing-robot-mobility-whole-body-control-with-ai-from-nvidia-research/\n",
      "https://developer.nvidia.com/blog/r2d2-advancing-robot-mobility-whole-body-control-with-ai-from-nvidia-research/\n",
      "https://nvidianews.nvidia.com/news/nvidia-releases-isaac-gr00t-n1-worlds-first-open-humanoid-robot-foundation-model-and-simulation-libraries\n",
      "https://nvidianews.nvidia.com/news/nvidia-releases-isaac-gr00t-n1-worlds-first-open-humanoid-robot-foundation-model-and-simulation-libraries\n",
      "https://www.nvidia.com/en-us/data-center/\n",
      "https://www.nvidia.com/en-us/data-center/gpu-cloud-computing/\n",
      "https://www.nvidia.com/en-us/edge-computing/\n",
      "https://build.nvidia.com/explore/discover\n",
      "https://www.nvidia.com/en-us/data-center/products/ai-enterprise/\n",
      "https://www.nvidia.com/en-us/data-center/dgx-systems/\n",
      "https://www.nvidia.com/en-us/data-center/products/certified-systems/\n",
      "https://eventmobi.com/website/coreweave\n",
      "https://eventmobi.com/website/coreweave\n",
      "https://www.se.com/ww/en/about-us/newsroom/news/press-releases.jsp?id=68432d51b96642343f0f890b\n",
      "https://www.se.com/ww/en/about-us/newsroom/news/press-releases.jsp?id=68432d51b96642343f0f890b\n",
      "https://blogs.nvidia.com/blog/nvidia-deutsche-telekom-germany-sovereign-ai/\n",
      "https://blogs.nvidia.com/blog/nvidia-deutsche-telekom-germany-sovereign-ai/\n",
      "https://blogs.nvidia.com/blog/european-telcos-ai-factories/\n",
      "https://blogs.nvidia.com/blog/european-telcos-ai-factories/\n",
      "https://blogs.nvidia.com/blog/blackwell-performance-mlperf-training/\n",
      "https://blogs.nvidia.com/blog/blackwell-performance-mlperf-training/\n",
      "https://blogs.nvidia.com/blog/dell-technologies-ai-factories-blackwell/\n",
      "https://blogs.nvidia.com/blog/dell-technologies-ai-factories-blackwell/\n",
      "https://www.g42.ai/resources/news/global-tech-alliance-launches-stargate-uae\n",
      "https://www.g42.ai/resources/news/global-tech-alliance-launches-stargate-uae\n",
      "https://blogs.nvidia.com/blog/microsoft-build-agentic-ai-innovation-cloud-pc/\n",
      "https://blogs.nvidia.com/blog/microsoft-build-agentic-ai-innovation-cloud-pc/\n",
      "https://nvidianews.nvidia.com/news/nvidia-launches-ai-first-dgx-personal-computing-systems-with-global-computer-makers\n",
      "https://nvidianews.nvidia.com/news/nvidia-launches-ai-first-dgx-personal-computing-systems-with-global-computer-makers\n",
      "https://blogs.nvidia.com/blog/storage-leaders-ai-data-platform-agents\n",
      "https://blogs.nvidia.com/blog/storage-leaders-ai-data-platform-agents\n",
      "https://www.nvidia.com/en-us/about-nvidia/\n",
      "https://www.nvidia.com/gtc/events/\n",
      "https://www.nvidia.com/en-us/about-nvidia/careers/\n",
      "https://nvidianews.nvidia.com\n",
      "https://www.nvidia.com/en-us/on-demand\n",
      "https://nvidianews.nvidia.com/bios\n",
      "https://www.nvidia.com/content/dam/en-zz/Solutions/about-nvidia/corporate-nvidia-in-brief.pdf\n",
      "https://images.nvidia.com/pdf/NVIDIA-Story.pdf\n",
      "https://www.nvidia.com/en-eu/gtc/keynote/\n",
      "https://www.nvidia.com/en-eu/gtc/keynote/\n",
      "https://www.nvidia.com/en-us/on-demand/\n",
      "https://www.nvidia.com/en-us/on-demand/\n",
      "https://www.youtube.com/watch?v=TEGAQxg1gVA\n",
      "https://www.youtube.com/watch?v=TEGAQxg1gVA\n",
      "https://images.nvidia.com/aem-dam/Solutions/homepage/pdf/NVIDIA-Story.pdf\n",
      "https://images.nvidia.com/aem-dam/Solutions/homepage/pdf/NVIDIA-Story.pdf\n",
      "https://www.nvidia.com/en-us/about-nvidia/\n",
      "https://www.nvidia.com/en-us/about-nvidia/\n",
      "https://blogs.nvidia.com/blog/accelerated-ai-energy-efficiency/\n",
      "https://blogs.nvidia.com/blog/accelerated-ai-energy-efficiency/\n",
      "https://blogs.nvidia.com/blog/ai-data-science-career-development/\n",
      "https://blogs.nvidia.com/blog/ai-data-science-career-development/\n",
      "https://blogs.nvidia.com/blog/selin-ornek-robot-guide-dogs/\n",
      "https://blogs.nvidia.com/blog/selin-ornek-robot-guide-dogs/\n",
      "https://docs.nvidia.com/smlib/manual/smlib/index.html\n",
      "https://docs.nvidia.com/smlib/manual/nlib/index.html\n",
      "#\n",
      "https://docs.deci.ai/\n",
      "#\n",
      "https://www.nvidia.com/en-us/about-nvidia/\n",
      "https://images.nvidia.com/aem-dam/Solutions/homepage/pdf/NVIDIA-Story.pdf\n",
      "https://investor.nvidia.com/home/default.aspx\n",
      "https://www.nventures.ai\n",
      "https://www.nvidia.com/en-us/foundation/\n",
      "https://www.nvidia.com/en-us/research/\n",
      "https://www.nvidia.com/en-us/sustainability/\n",
      "https://www.nvidia.com/en-us/technologies/\n",
      "https://www.nvidia.com/en-us/about-nvidia/careers/\n",
      "https://nvidianews.nvidia.com/\n",
      "https://blogs.nvidia.com/\n",
      "https://developer.nvidia.com/blog/\n",
      "https://www.nvidia.com/en-us/about-nvidia/webinar-portal/\n",
      "https://www.nvidia.com/en-us/preferences/email-signup/\n",
      "https://www.nvidia.com/en-us/events/\n",
      "https://www.nvidia.com/gtc/events/\n",
      "https://www.nvidia.com/en-us/on-demand/\n",
      "https://developer.nvidia.com/\n",
      "https://www.nvidia.com/en-us/about-nvidia/partners/\n",
      "https://www.nvidia.com/en-us/executive-insights/\n",
      "https://www.nvidia.com/en-us/startups/\n",
      "https://www.nvidia.com/en-us/programs/isv/\n",
      "https://docs.nvidia.com/\n",
      "https://www.nvidia.com/en-us/training/\n",
      "https://academy.nvidia.com/en/\n",
      "https://www.nvidia.com/en-us/support/enterprise/advisory-services/\n",
      "https://www.nvidia.com/en-us/preferences/email-signup/\n",
      "https://www.facebook.com/NVIDIA\n",
      "https://www.instagram.com/nvidia/?hl=en\n",
      "https://www.linkedin.com/company/nvidia/\n",
      "https://twitter.com/nvidia\n",
      "https://www.youtube.com/user/nvidia\n",
      "https://www.nvidia.com/en-us/location-selector/\n",
      "https://www.nvidia.com/en-us/about-nvidia/privacy-policy/\n",
      "https://www.nvidia.com/en-us/about-nvidia/privacy-center/\n",
      "https://www.nvidia.com/en-us/preferences/email-preferences/\n",
      "https://www.nvidia.com/en-us/about-nvidia/terms-of-service/\n",
      "https://www.nvidia.com/en-us/about-nvidia/accessibility/\n",
      "https://www.nvidia.com/en-us/about-nvidia/company-policies/\n",
      "https://www.nvidia.com/en-us/product-security/\n",
      "https://www.nvidia.com/en-us/contact/\n"
     ]
    }
   ],
   "source": [
    "print(get_links_user_prompt(websiteContent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a29aca19-ca13-471c-a4b4-5abbfa813f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links(url):\n",
    "    website = Website(url)\n",
    "    response = openai.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": link_system_prompt},\n",
    "            {\"role\": \"user\", \"content\": get_links_user_prompt(website)}\n",
    "      ],\n",
    "        response_format={\"type\": \"json_object\"}\n",
    "    )\n",
    "    result = response.choices[0].message.content\n",
    "    return json.loads(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74a827a0-2782-4ae5-b210-4a242a8b4cc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/',\n",
       " '/models',\n",
       " '/datasets',\n",
       " '/spaces',\n",
       " '/docs',\n",
       " '/enterprise',\n",
       " '/pricing',\n",
       " '/login',\n",
       " '/join',\n",
       " '/spaces',\n",
       " '/models',\n",
       " '/black-forest-labs/FLUX.1-Kontext-dev',\n",
       " '/tencent/Hunyuan-A13B-Instruct',\n",
       " '/google/magenta-realtime',\n",
       " '/nanonets/Nanonets-OCR-s',\n",
       " '/google/gemma-3n-E4B-it',\n",
       " '/models',\n",
       " '/spaces/enzostvs/deepsite',\n",
       " '/spaces/ilcve21/Sparc3D',\n",
       " '/spaces/OmniGen2/OmniGen2',\n",
       " '/spaces/tencent/Hunyuan3D-2.1',\n",
       " '/spaces/black-forest-labs/FLUX.1-Kontext-Dev',\n",
       " '/spaces',\n",
       " '/datasets/fka/awesome-chatgpt-prompts',\n",
       " '/datasets/institutional/institutional-books-1.0',\n",
       " '/datasets/EssentialAI/essential-web-v1.0',\n",
       " '/datasets/facebook/seamless-interaction',\n",
       " '/datasets/FreedomIntelligence/ShareGPT-4o-Image',\n",
       " '/datasets',\n",
       " '/join',\n",
       " '/pricing#endpoints',\n",
       " '/pricing#spaces',\n",
       " '/pricing',\n",
       " '/enterprise',\n",
       " '/enterprise',\n",
       " '/enterprise',\n",
       " '/enterprise',\n",
       " '/enterprise',\n",
       " '/enterprise',\n",
       " '/enterprise',\n",
       " '/allenai',\n",
       " '/facebook',\n",
       " '/amazon',\n",
       " '/google',\n",
       " '/Intel',\n",
       " '/microsoft',\n",
       " '/grammarly',\n",
       " '/Writer',\n",
       " '/docs/transformers',\n",
       " '/docs/diffusers',\n",
       " '/docs/safetensors',\n",
       " '/docs/huggingface_hub',\n",
       " '/docs/tokenizers',\n",
       " '/docs/trl',\n",
       " '/docs/transformers.js',\n",
       " '/docs/smolagents',\n",
       " '/docs/peft',\n",
       " '/docs/datasets',\n",
       " '/docs/text-generation-inference',\n",
       " '/docs/accelerate',\n",
       " '/models',\n",
       " '/datasets',\n",
       " '/spaces',\n",
       " '/changelog',\n",
       " 'https://endpoints.huggingface.co',\n",
       " '/chat',\n",
       " '/huggingface',\n",
       " '/brand',\n",
       " '/terms-of-service',\n",
       " '/privacy',\n",
       " 'https://apply.workable.com/huggingface/',\n",
       " 'mailto:press@huggingface.co',\n",
       " '/learn',\n",
       " '/docs',\n",
       " '/blog',\n",
       " 'https://discuss.huggingface.co',\n",
       " 'https://status.huggingface.co/',\n",
       " 'https://github.com/huggingface',\n",
       " 'https://twitter.com/huggingface',\n",
       " 'https://www.linkedin.com/company/huggingface/',\n",
       " '/join/discord',\n",
       " 'https://www.zhihu.com/org/huggingface',\n",
       " 'https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/chinese-language-blog/wechat.jpg']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Anthropic has made their site harder to scrape, so I'm using HuggingFace..\n",
    "\n",
    "huggingface = Website(\"https://huggingface.co\")\n",
    "huggingface.links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3d583e2-dcc4-40cc-9b28-1e8dbf402924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'links': [{'type': 'about page', 'url': 'https://huggingface.co/huggingface'},\n",
       "  {'type': 'careers page', 'url': 'https://apply.workable.com/huggingface/'},\n",
       "  {'type': 'blog', 'url': 'https://huggingface.co/blog'},\n",
       "  {'type': 'company page',\n",
       "   'url': 'https://www.linkedin.com/company/huggingface/'},\n",
       "  {'type': 'discussion forum', 'url': 'https://discuss.huggingface.co'},\n",
       "  {'type': 'status page', 'url': 'https://status.huggingface.co/'}]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_links(\"https://huggingface.co\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d74128e-dfb6-47ec-9549-288b621c838c",
   "metadata": {},
   "source": [
    "## Second step: make the brochure!\n",
    "\n",
    "Assemble all the details into another prompt to GPT4-o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "85a5b6e2-e7ef-44a9-bc7f-59ede71037b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_details(url):\n",
    "    result = \"Landing page:\\n\"\n",
    "    result += Website(url).get_contents()\n",
    "    links = get_links(url)\n",
    "    print(\"Found links:\", links)\n",
    "    for link in links[\"links\"]:\n",
    "        result += f\"\\n\\n{link['type']}\\n\"\n",
    "        result += Website(link[\"url\"]).get_contents()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5099bd14-076d-4745-baf3-dac08d8e5ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found links: {'links': [{'type': 'about page', 'url': 'https://huggingface.co/about'}, {'type': 'company page', 'url': 'https://huggingface.co/enterprise'}, {'type': 'careers page', 'url': 'https://apply.workable.com/huggingface/'}, {'type': 'blog page', 'url': 'https://huggingface.co/blog'}, {'type': 'community page', 'url': 'https://discuss.huggingface.co'}, {'type': 'GitHub page', 'url': 'https://github.com/huggingface'}, {'type': 'Twitter page', 'url': 'https://twitter.com/huggingface'}, {'type': 'LinkedIn page', 'url': 'https://www.linkedin.com/company/huggingface/'}]}\n",
      "Landing page:\n",
      "Webpage Title:\n",
      "Hugging Face  The AI community building the future.\n",
      "Webpage Contents:\n",
      "Hugging Face\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Community\n",
      "Docs\n",
      "Enterprise\n",
      "Pricing\n",
      "Log In\n",
      "Sign Up\n",
      "The AI community building the future.\n",
      "The platform where the machine learning community collaborates on models, datasets, and applications.\n",
      "Explore AI Apps\n",
      "or\n",
      "Browse 1M+ models\n",
      "Trending on\n",
      "this week\n",
      "Models\n",
      "black-forest-labs/FLUX.1-Kontext-dev\n",
      "Updated\n",
      "about 18 hours ago\n",
      "\n",
      "12.9k\n",
      "\n",
      "826\n",
      "tencent/Hunyuan-A13B-Instruct\n",
      "Updated\n",
      "about 12 hours ago\n",
      "\n",
      "452\n",
      "google/magenta-realtime\n",
      "Updated\n",
      "5 days ago\n",
      "\n",
      "390\n",
      "nanonets/Nanonets-OCR-s\n",
      "Updated\n",
      "8 days ago\n",
      "\n",
      "202k\n",
      "\n",
      "1.22k\n",
      "google/gemma-3n-E4B-it\n",
      "Updated\n",
      "1 day ago\n",
      "\n",
      "5.55k\n",
      "\n",
      "222\n",
      "Browse 1M+ models\n",
      "Spaces\n",
      "Running\n",
      "8.75k\n",
      "8.75k\n",
      "DeepSite v2\n",
      "\n",
      "Generate any application with DeepSeek\n",
      "Running\n",
      "865\n",
      "865\n",
      "Sparc3D\n",
      "\n",
      "Next-Gen High-Resolution 3D Model Generation\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "274\n",
      "274\n",
      "OmniGen2\n",
      "\n",
      "OmniGen2: Unified Image Understanding and Generation.\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "522\n",
      "522\n",
      "Hunyuan3D-2.1\n",
      "\n",
      "Image-to-3D Generation\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "MCP\n",
      "187\n",
      "187\n",
      "FLUX.1 Kontext\n",
      "\n",
      "Kontext image editing on FLUX[dev]\n",
      "Browse 400k+ applications\n",
      "Datasets\n",
      "fka/awesome-chatgpt-prompts\n",
      "Updated\n",
      "Jan 6\n",
      "\n",
      "22.9k\n",
      "\n",
      "8.06k\n",
      "institutional/institutional-books-1.0\n",
      "Updated\n",
      "12 days ago\n",
      "\n",
      "38.2k\n",
      "\n",
      "199\n",
      "EssentialAI/essential-web-v1.0\n",
      "Updated\n",
      "6 days ago\n",
      "\n",
      "75.5k\n",
      "\n",
      "162\n",
      "facebook/seamless-interaction\n",
      "Updated\n",
      "about 24 hours ago\n",
      "\n",
      "1\n",
      "\n",
      "35\n",
      "FreedomIntelligence/ShareGPT-4o-Image\n",
      "Updated\n",
      "about 12 hours ago\n",
      "\n",
      "75\n",
      "\n",
      "32\n",
      "Browse 250k+ datasets\n",
      "The Home of Machine Learning\n",
      "Create, discover and collaborate on ML better.\n",
      "The collaboration platform\n",
      "Host and collaborate on unlimited public models, datasets and applications.\n",
      "Move faster\n",
      "With the HF Open source stack.\n",
      "Explore all modalities\n",
      "Text, image, video, audio or even 3D.\n",
      "Build your portfolio\n",
      "Share your work with the world and build your ML profile.\n",
      "Sign Up\n",
      "Accelerate your ML\n",
      "We provide paid Compute and Enterprise solutions.\n",
      "Compute\n",
      "Deploy on optimized\n",
      "Inference Endpoints\n",
      "or update your\n",
      "Spaces applications\n",
      "to a GPU in a few clicks.\n",
      "View pricing\n",
      "Starting at $0.60/hour for GPU\n",
      "Enterprise\n",
      "Give your team the most advanced platform to build AI with enterprise-grade security, access controls and\n",
      "\t\t\tdedicated support.\n",
      "Getting started\n",
      "Starting at $20/user/month\n",
      "Single Sign-On\n",
      "Regions\n",
      "Priority Support\n",
      "Audit Logs\n",
      "Resource Groups\n",
      "Private Datasets Viewer\n",
      "More than 50,000 organizations are using Hugging Face\n",
      "Ai2\n",
      "Enterprise\n",
      "non-profit\n",
      "\n",
      "766 models\n",
      "\n",
      "3.5k followers\n",
      "AI at Meta\n",
      "Enterprise\n",
      "company\n",
      "\n",
      "2.17k models\n",
      "\n",
      "6.61k followers\n",
      "Amazon\n",
      "company\n",
      "\n",
      "20 models\n",
      "\n",
      "3.26k followers\n",
      "Google\n",
      "company\n",
      "\n",
      "1.01k models\n",
      "\n",
      "17.7k followers\n",
      "Intel\n",
      "company\n",
      "\n",
      "207 models\n",
      "\n",
      "2.68k followers\n",
      "Microsoft\n",
      "company\n",
      "\n",
      "395 models\n",
      "\n",
      "13.2k followers\n",
      "Grammarly\n",
      "Team\n",
      "company\n",
      "\n",
      "10 models\n",
      "\n",
      "166 followers\n",
      "Writer\n",
      "Enterprise\n",
      "company\n",
      "\n",
      "21 models\n",
      "\n",
      "302 followers\n",
      "Our Open Source\n",
      "We are building the foundation of ML tooling with the community.\n",
      "Transformers\n",
      "146,158\n",
      "State-of-the-art ML for PyTorch, TensorFlow, JAX\n",
      "Diffusers\n",
      "29,534\n",
      "State-of-the-art Diffusion models in PyTorch\n",
      "Safetensors\n",
      "3,329\n",
      "Safe way to store/distribute neural network weights\n",
      "Hub Python Library\n",
      "2,721\n",
      "Python client to interact with the Hugging Face Hub\n",
      "Tokenizers\n",
      "9,847\n",
      "Fast tokenizers optimized for research & production\n",
      "TRL\n",
      "14,365\n",
      "Train transformers LMs with reinforcement learning\n",
      "Transformers.js\n",
      "13,912\n",
      "State-of-the-art ML running directly in your browser\n",
      "smolagents\n",
      "20,661\n",
      "Smol library to build great agents in Python\n",
      "PEFT\n",
      "18,875\n",
      "Parameter-efficient finetuning for large language models\n",
      "Datasets\n",
      "20,310\n",
      "Access & share datasets for any ML tasks\n",
      "Text Generation Inference\n",
      "10,261\n",
      "Serve language models with TGI optimized toolkit\n",
      "Accelerate\n",
      "8,876\n",
      "Train PyTorch models with multi-GPU, TPU, mixed precision\n",
      "System theme\n",
      "Website\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Changelog\n",
      "Inference Endpoints\n",
      "HuggingChat\n",
      "Company\n",
      "About\n",
      "Brand assets\n",
      "Terms of service\n",
      "Privacy\n",
      "Jobs\n",
      "Press\n",
      "Resources\n",
      "Learn\n",
      "Documentation\n",
      "Blog\n",
      "Forum\n",
      "Service Status\n",
      "Social\n",
      "GitHub\n",
      "Twitter\n",
      "LinkedIn\n",
      "Discord\n",
      "\n",
      "\n",
      "\n",
      "about page\n",
      "Webpage Title:\n",
      "about (Sergei)\n",
      "Webpage Contents:\n",
      "Hugging Face\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Community\n",
      "Docs\n",
      "Enterprise\n",
      "Pricing\n",
      "Log In\n",
      "Sign Up\n",
      "Sergei\n",
      "about\n",
      "Follow\n",
      "selvivincent's profile picture\n",
      "Kalaipriya's profile picture\n",
      "Renumathi's profile picture\n",
      "5\n",
      "\t\t\t\t\tfollowers\n",
      "\n",
      "0 following\n",
      "AI & ML interests\n",
      "None yet\n",
      "Organizations\n",
      "None yet\n",
      "models\n",
      "0\n",
      "None public yet\n",
      "datasets\n",
      "0\n",
      "None public yet\n",
      "System theme\n",
      "Company\n",
      "TOS\n",
      "Privacy\n",
      "About\n",
      "Jobs\n",
      "Website\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Pricing\n",
      "Docs\n",
      "\n",
      "\n",
      "\n",
      "company page\n",
      "Webpage Title:\n",
      "Enterprise Hub - Hugging Face\n",
      "Webpage Contents:\n",
      "Hugging Face\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Community\n",
      "Docs\n",
      "Enterprise\n",
      "Pricing\n",
      "Log In\n",
      "Sign Up\n",
      "Team & Enterprise Hub\n",
      "Scale your organization with the worlds leading AI platform\n",
      "Subscribe to\n",
      "Team\n",
      "starting at $20/user/month\n",
      "or\n",
      "Contact sales for\n",
      "Enterprise\n",
      "to explore flexible contract options\n",
      "Give your organization the most advanced platform to build AI with enterprise-grade security, access controls,\n",
      "\t\t\tdedicated support and more.\n",
      "Single Sign-On\n",
      "Connect securely to your identity provider with SSO integration.\n",
      "Regions\n",
      "Select, manage, and audit the location of your repository data.\n",
      "Audit Logs\n",
      "Stay in control with comprehensive logs that report on actions taken.\n",
      "Resource Groups\n",
      "Accurately manage access to repositories with granular access control.\n",
      "Token Management\n",
      "Centralized token control and custom approval policies for organization access.\n",
      "Analytics\n",
      "Track and analyze repository usage data in a single dashboard.\n",
      "Advanced Compute Options\n",
      "Increase scalability and performance with more compute options like ZeroGPU.\n",
      "ZeroGPU Quota Boost\n",
      "All organization members get 5x more ZeroGPU quota to get the most of Spaces.\n",
      "Private Datasets Viewer\n",
      "Enable the Dataset Viewer on your private datasets for easier collaboration.\n",
      "Private Storage\n",
      "Get an additional 1 TB of private storage for each member of your organization (then $25/month per extra TB).\n",
      "Inference Providers\n",
      "Enable organization billing for Inference Providers, monitor usage with analytics, and manage spending limits.\n",
      "Advanced security\n",
      "Configure organization-wide security policies and default repository visibility.\n",
      "Billing\n",
      "Control your budget effectively with managed billing and yearly commit options.\n",
      "Priority Support\n",
      "Maximize your platform usage with priority support from the Hugging Face team.\n",
      "Join the most forward-thinking AI organizations\n",
      "Everything you already know and love about Hugging Face in Enterprise mode.\n",
      "Subscribe to\n",
      "Team\n",
      "starting at $20/user/month\n",
      "or\n",
      "Contact sales for\n",
      "Enterprise\n",
      "to explore flexible contract options\n",
      "NVIDIA\n",
      "Enterprise\n",
      "company\n",
      "\n",
      "416 models\n",
      "\n",
      "30.3k followers\n",
      "AI at Meta\n",
      "Enterprise\n",
      "company\n",
      "\n",
      "2.17k models\n",
      "\n",
      "6.61k followers\n",
      "Snowflake\n",
      "Enterprise\n",
      "company\n",
      "\n",
      "23 models\n",
      "\n",
      "552 followers\n",
      "Arm\n",
      "Enterprise\n",
      "company\n",
      "\n",
      "224 followers\n",
      "Qwen\n",
      "Team\n",
      "company\n",
      "\n",
      "321 models\n",
      "\n",
      "36.5k followers\n",
      "LiveRAG by AIIR\n",
      "Team\n",
      "company\n",
      "\n",
      "129 followers\n",
      "Nutanix\n",
      "Enterprise\n",
      "company\n",
      "\n",
      "261 models\n",
      "\n",
      "111 followers\n",
      "Jusbrasil\n",
      "Team\n",
      "company\n",
      "\n",
      "98 followers\n",
      "creditkarma\n",
      "Enterprise\n",
      "company\n",
      "\n",
      "73 followers\n",
      "H2O.ai\n",
      "Team\n",
      "company\n",
      "\n",
      "71 models\n",
      "\n",
      "432 followers\n",
      "Grammarly\n",
      "Team\n",
      "company\n",
      "\n",
      "10 models\n",
      "\n",
      "166 followers\n",
      "BAIDU\n",
      "Team\n",
      "company\n",
      "\n",
      "367 followers\n",
      "Roblox Corporation\n",
      "Enterprise\n",
      "company\n",
      "\n",
      "3 models\n",
      "\n",
      "242 followers\n",
      "BCG X\n",
      "Team\n",
      "company\n",
      "\n",
      "40 followers\n",
      "Meta Llama\n",
      "Enterprise\n",
      "company\n",
      "\n",
      "70 models\n",
      "\n",
      "50k followers\n",
      "Nerdy Face\n",
      "Enterprise\n",
      "company\n",
      "\n",
      "1 model\n",
      "\n",
      "303 followers\n",
      "Orange\n",
      "Enterprise\n",
      "company\n",
      "\n",
      "7 models\n",
      "\n",
      "244 followers\n",
      "Writer\n",
      "Enterprise\n",
      "company\n",
      "\n",
      "21 models\n",
      "\n",
      "302 followers\n",
      "ServiceNow\n",
      "Enterprise\n",
      "company\n",
      "\n",
      "516 followers\n",
      "ServiceNow-AI\n",
      "Enterprise\n",
      "company\n",
      "\n",
      "3 models\n",
      "\n",
      "290 followers\n",
      "Fidelity Investments\n",
      "Enterprise\n",
      "company\n",
      "\n",
      "151 followers\n",
      "TNG Technology Consulting GmbH\n",
      "Team\n",
      "company\n",
      "\n",
      "4 models\n",
      "\n",
      "158 followers\n",
      "Technology Innovation Institute\n",
      "Team\n",
      "company\n",
      "\n",
      "101 models\n",
      "\n",
      "1.46k followers\n",
      "HyperCLOVA X\n",
      "Team\n",
      "company\n",
      "\n",
      "3 models\n",
      "\n",
      "370 followers\n",
      "HiddenLayer\n",
      "Team\n",
      "company\n",
      "\n",
      "1 model\n",
      "\n",
      "74 followers\n",
      "LinkedIn\n",
      "Enterprise\n",
      "company\n",
      "\n",
      "65 followers\n",
      "Lightricks\n",
      "Team\n",
      "company\n",
      "\n",
      "13 models\n",
      "\n",
      "1.09k followers\n",
      "Novo Nordisk R&ED\n",
      "Team\n",
      "company\n",
      "\n",
      "37 followers\n",
      "Shopify\n",
      "Enterprise\n",
      "company\n",
      "\n",
      "484 followers\n",
      "AMD\n",
      "Enterprise\n",
      "company\n",
      "\n",
      "145 models\n",
      "\n",
      "1.63k followers\n",
      "JetBrains\n",
      "Team\n",
      "company\n",
      "\n",
      "10 models\n",
      "\n",
      "584 followers\n",
      "Together\n",
      "Team\n",
      "company\n",
      "\n",
      "33 models\n",
      "\n",
      "629 followers\n",
      "Xsolla\n",
      "Enterprise\n",
      "company\n",
      "\n",
      "143 followers\n",
      "Toyota Research Institute\n",
      "Team\n",
      "company\n",
      "\n",
      "10 models\n",
      "\n",
      "124 followers\n",
      "Deutsche Telekom AG\n",
      "Enterprise\n",
      "company\n",
      "\n",
      "7 models\n",
      "\n",
      "156 followers\n",
      "IBM Granite\n",
      "Team\n",
      "company\n",
      "\n",
      "125 models\n",
      "\n",
      "1.98k followers\n",
      "Aledade Inc\n",
      "Enterprise\n",
      "+\n",
      "company\n",
      "\n",
      "72 followers\n",
      "Chegg Inc\n",
      "Enterprise\n",
      "company\n",
      "\n",
      "87 followers\n",
      "MiniMax\n",
      "Team\n",
      "company\n",
      "\n",
      "8 models\n",
      "\n",
      "1.39k followers\n",
      "Liquid AI\n",
      "Team\n",
      "company\n",
      "\n",
      "212 followers\n",
      "Twelve Labs\n",
      "Team\n",
      "company\n",
      "\n",
      "49 followers\n",
      "Stability AI\n",
      "Team\n",
      "company\n",
      "\n",
      "108 models\n",
      "\n",
      "25.9k followers\n",
      "Compliance & Certifications\n",
      "GDPR Compliant\n",
      "SOC 2 Type 2\n",
      "System theme\n",
      "Website\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Changelog\n",
      "Inference Endpoints\n",
      "HuggingChat\n",
      "Company\n",
      "About\n",
      "Brand assets\n",
      "Terms of service\n",
      "Privacy\n",
      "Jobs\n",
      "Press\n",
      "Resources\n",
      "Learn\n",
      "Documentation\n",
      "Blog\n",
      "Forum\n",
      "Service Status\n",
      "Social\n",
      "GitHub\n",
      "Twitter\n",
      "LinkedIn\n",
      "Discord\n",
      "\n",
      "\n",
      "\n",
      "careers page\n",
      "Webpage Title:\n",
      "Hugging Face - Current Openings\n",
      "Webpage Contents:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "blog page\n",
      "Webpage Title:\n",
      "Hugging Face  Blog\n",
      "Webpage Contents:\n",
      "Hugging Face\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Community\n",
      "Docs\n",
      "Enterprise\n",
      "Pricing\n",
      "Log In\n",
      "Sign Up\n",
      "Blog, Articles, and discussions\n",
      "New Article\n",
      "Everything\n",
      "community\n",
      "guide\n",
      "open source collab\n",
      "partnerships\n",
      "research\n",
      "NLP\n",
      "Audio\n",
      "CV\n",
      "RL\n",
      "ethics\n",
      "Diffusion\n",
      "Game Development\n",
      "RLHF\n",
      "Leaderboard\n",
      "Case Studies\n",
      "LeRobot\n",
      "Inference Providers\n",
      "Gemma 3n fully available in the open-source ecosystem!\n",
      "By\n",
      "ariG23498\n",
      "June 26, 2025\n",
      "\n",
      "81\n",
      "Community Articles\n",
      "view all\n",
      " Kimi-VL-A3B-Thinking-2506: A Quick Navigation\n",
      "By\n",
      "moonshotai\n",
      "and 1 other\n",
      "\n",
      "7 days ago\n",
      "\n",
      "51\n",
      "Code a simple RAG from scratch\n",
      "By\n",
      "ngxson\n",
      "\n",
      "Oct 29, 2024\n",
      "\n",
      "112\n",
      "DeepSeek-R1 Dissection: Understanding PPO & GRPO Without Any Prior Reinforcement Learning Knowledge\n",
      "By\n",
      "NormalUhr\n",
      "\n",
      "Feb 7\n",
      "\n",
      "170\n",
      "Accelerating AI for Drug Discovery: Ginkgos GDPx Functional Genomics and GDPa Antibody Developability Dataset Series\n",
      "By\n",
      "cgeorgiaw\n",
      "and 1 other\n",
      "\n",
      "4 days ago\n",
      "\n",
      "11\n",
      "Welcome the NVIDIA Llama Nemotron Nano VLM to Hugging Face Hub\n",
      "By\n",
      "nvidia\n",
      "and 10 others\n",
      "\n",
      "about 18 hours ago\n",
      "\n",
      "10\n",
      "The Anthropic Ruling: Why AI Training Just Got Legal (But Piracy Didn't)\n",
      "By\n",
      "fdaudens\n",
      "\n",
      "4 days ago\n",
      "\n",
      "9\n",
      "Uncensor any LLM with abliteration\n",
      "By\n",
      "mlabonne\n",
      "\n",
      "Jun 13, 2024\n",
      "\n",
      "618\n",
      "Combining Remote Reasoning with Local Models\n",
      "By\n",
      "burtenshaw\n",
      "\n",
      "2 days ago\n",
      "\n",
      "8\n",
      "Why Maybe We're Measuring LLM Compression Wrong\n",
      "By\n",
      "rishiraj\n",
      "\n",
      "7 days ago\n",
      "\n",
      "7\n",
      "Automated Discovery of High-Performance GPU Kernels with OpenEvolve\n",
      "By\n",
      "codelion\n",
      "\n",
      "about 16 hours ago\n",
      "\n",
      "7\n",
      "Fine-tune Llama 3.1 Ultra-Efficiently with Unsloth\n",
      "By\n",
      "mlabonne\n",
      "\n",
      "Jul 29, 2024\n",
      "\n",
      "343\n",
      "Mastering Tensor Dimensions in Transformers\n",
      "By\n",
      "not-lain\n",
      "\n",
      "Jan 12\n",
      "\n",
      "73\n",
      "KV Caching Explained: Optimizing Transformer Inference Efficiency\n",
      "By\n",
      "not-lain\n",
      "\n",
      "Jan 30\n",
      "\n",
      "87\n",
      "What Coding Agent Wins?\n",
      "By\n",
      "Kseniase\n",
      "and 1 other\n",
      "\n",
      "2 days ago\n",
      "\n",
      "6\n",
      "ColPali: Efficient Document Retrieval with Vision Language Models \n",
      "By\n",
      "manu\n",
      "\n",
      "Jul 5, 2024\n",
      "\n",
      "266\n",
      "#14: What Is MCP, and Why Is Everyone  Suddenly! Talking About It?\n",
      "By\n",
      "Kseniase\n",
      "\n",
      "Mar 17\n",
      "\n",
      "297\n",
      "Whose Voice Do We Hear When AI Speaks?\n",
      "By\n",
      "giadap\n",
      "\n",
      "8 days ago\n",
      "\n",
      "10\n",
      "Adaptive Classifier: Dynamic Text Classification with Continuous Learning\n",
      "By\n",
      "codelion\n",
      "\n",
      "8 days ago\n",
      "\n",
      "12\n",
      "DO THEY SEE WHAT WE SEE?\n",
      "By\n",
      "felfri\n",
      "\n",
      "6 days ago\n",
      "\n",
      "5\n",
      "Nano-vLLM meets Inference Endpoints\n",
      "By\n",
      "angt\n",
      "\n",
      "3 days ago\n",
      "\n",
      "5\n",
      "Transformers backend integration in SGLang\n",
      "By\n",
      "marcsun13\n",
      "June 23, 2025\n",
      "\n",
      "36\n",
      "(LoRA) Fine-Tuning FLUX.1-dev on Consumer Hardware\n",
      "By\n",
      "derekl35\n",
      "June 19, 2025\n",
      "\n",
      "66\n",
      "Groq on Hugging Face Inference Providers \n",
      "By\n",
      "sbrandeis\n",
      "June 16, 2025\n",
      "\n",
      "34\n",
      "Enhance Your Models in 5 Minutes with the Hugging Face Kernel Hub\n",
      "By\n",
      "drbh\n",
      "June 12, 2025\n",
      "\n",
      "101\n",
      "Featherless AI on Hugging Face Inference Providers \n",
      "By\n",
      "sbrandeis\n",
      "June 12, 2025\n",
      "\n",
      "41\n",
      "Introducing Training Cluster as a Service - a new collaboration with NVIDIA\n",
      "By\n",
      "jeffboudier\n",
      "June 11, 2025\n",
      "\n",
      "23\n",
      "ScreenSuite - The most comprehensive evaluation suite for GUI Agents!\n",
      "By\n",
      "a-mahla\n",
      "June 6, 2025\n",
      "\n",
      "49\n",
      "KV Cache from scratch in nanoVLM\n",
      "By\n",
      "ariG23498\n",
      "June 4, 2025\n",
      "\n",
      "79\n",
      "SmolVLA: Efficient Vision-Language-Action Model trained on Lerobot Community Data\n",
      "By\n",
      "danaaubakirova\n",
      "June 3, 2025\n",
      "\n",
      "167\n",
      "No GPU left behind: Unlocking Efficiency with Co-located vLLM in TRL\n",
      "By\n",
      "toslali-ibm\n",
      "June 3, 2025\n",
      "guest\n",
      "\n",
      "60\n",
      "CodeAgents + Structure: A Better Way to Execute Actions\n",
      "By\n",
      "akseljoonas\n",
      "May 28, 2025\n",
      "\n",
      "61\n",
      " Liger GRPO meets TRL\n",
      "By\n",
      "shisahni\n",
      "May 25, 2025\n",
      "guest\n",
      "\n",
      "44\n",
      "Dell Enterprise Hub is all you need to build AI on premises\n",
      "By\n",
      "jeffboudier\n",
      "May 23, 2025\n",
      "\n",
      "19\n",
      "Tiny Agents in Python: a MCP-powered agent in ~70 lines of code\n",
      "By\n",
      "celinah\n",
      "May 23, 2025\n",
      "\n",
      "137\n",
      "Previous\n",
      "1\n",
      "2\n",
      "3\n",
      "...\n",
      "43\n",
      "Next\n",
      "Community Articles\n",
      "Sort:\n",
      "\t\tTrending\n",
      " Kimi-VL-A3B-Thinking-2506: A Quick Navigation\n",
      "By\n",
      "moonshotai\n",
      "and 1 other\n",
      "\n",
      "7 days ago\n",
      "\n",
      "51\n",
      "Code a simple RAG from scratch\n",
      "By\n",
      "ngxson\n",
      "\n",
      "Oct 29, 2024\n",
      "\n",
      "112\n",
      "DeepSeek-R1 Dissection: Understanding PPO & GRPO Without Any Prior Reinforcement Learning Knowledge\n",
      "By\n",
      "NormalUhr\n",
      "\n",
      "Feb 7\n",
      "\n",
      "170\n",
      "Accelerating AI for Drug Discovery: Ginkgos GDPx Functional Genomics and GDPa Antibody Developability Dataset Series\n",
      "By\n",
      "cgeorgiaw\n",
      "and 1 other\n",
      "\n",
      "4 days ago\n",
      "\n",
      "11\n",
      "Welcome the NVIDIA Llama Nemotron Nano VLM to Hugging Face Hub\n",
      "By\n",
      "nvidia\n",
      "and 10 others\n",
      "\n",
      "about 18 hours ago\n",
      "\n",
      "10\n",
      "The Anthropic Ruling: Why AI Training Just Got Legal (But Piracy Didn't)\n",
      "By\n",
      "fdaudens\n",
      "\n",
      "4 days ago\n",
      "\n",
      "9\n",
      "Uncensor any LLM with abliteration\n",
      "By\n",
      "mlabonne\n",
      "\n",
      "Jun 13, 2024\n",
      "\n",
      "618\n",
      "Combining Remote Reasoning with Local Models\n",
      "By\n",
      "burtenshaw\n",
      "\n",
      "2 days ago\n",
      "\n",
      "8\n",
      "Why Maybe We're Measuring LLM Compression Wrong\n",
      "By\n",
      "rishiraj\n",
      "\n",
      "7 days ago\n",
      "\n",
      "7\n",
      "Automated Discovery of High-Performance GPU Kernels with OpenEvolve\n",
      "By\n",
      "codelion\n",
      "\n",
      "about 16 hours ago\n",
      "\n",
      "7\n",
      "Fine-tune Llama 3.1 Ultra-Efficiently with Unsloth\n",
      "By\n",
      "mlabonne\n",
      "\n",
      "Jul 29, 2024\n",
      "\n",
      "343\n",
      "Mastering Tensor Dimensions in Transformers\n",
      "By\n",
      "not-lain\n",
      "\n",
      "Jan 12\n",
      "\n",
      "73\n",
      "KV Caching Explained: Optimizing Transformer Inference Efficiency\n",
      "By\n",
      "not-lain\n",
      "\n",
      "Jan 30\n",
      "\n",
      "87\n",
      "What Coding Agent Wins?\n",
      "By\n",
      "Kseniase\n",
      "and 1 other\n",
      "\n",
      "2 days ago\n",
      "\n",
      "6\n",
      "ColPali: Efficient Document Retrieval with Vision Language Models \n",
      "By\n",
      "manu\n",
      "\n",
      "Jul 5, 2024\n",
      "\n",
      "266\n",
      "#14: What Is MCP, and Why Is Everyone  Suddenly! Talking About It?\n",
      "By\n",
      "Kseniase\n",
      "\n",
      "Mar 17\n",
      "\n",
      "297\n",
      "Whose Voice Do We Hear When AI Speaks?\n",
      "By\n",
      "giadap\n",
      "\n",
      "8 days ago\n",
      "\n",
      "10\n",
      "Adaptive Classifier: Dynamic Text Classification with Continuous Learning\n",
      "By\n",
      "codelion\n",
      "\n",
      "8 days ago\n",
      "\n",
      "12\n",
      "DO THEY SEE WHAT WE SEE?\n",
      "By\n",
      "felfri\n",
      "\n",
      "6 days ago\n",
      "\n",
      "5\n",
      "Nano-vLLM meets Inference Endpoints\n",
      "By\n",
      "angt\n",
      "\n",
      "3 days ago\n",
      "\n",
      "5\n",
      "View all\n",
      "System theme\n",
      "Company\n",
      "TOS\n",
      "Privacy\n",
      "About\n",
      "Jobs\n",
      "Website\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Pricing\n",
      "Docs\n",
      "\n",
      "\n",
      "\n",
      "community page\n",
      "Webpage Title:\n",
      "Hugging Face Forums - Hugging Face Community Discussion\n",
      "Webpage Contents:\n",
      "Hugging Face Forums\n",
      "Topic\n",
      "Replies\n",
      "Views\n",
      "Activity\n",
      "TypeError: InferenceClient.text_generation() got an unexpected keyword argument\n",
      "Beginners\n",
      "1\n",
      "5\n",
      "June 28, 2025\n",
      "Text classification of RSS articles\n",
      "Beginners\n",
      "1\n",
      "5\n",
      "June 28, 2025\n",
      "Is a Pro account 5x or 8x ZeroGPU Quota?\n",
      "Beginners\n",
      "2\n",
      "11\n",
      "June 28, 2025\n",
      "How can I search models by architecture?\n",
      "Beginners\n",
      "3\n",
      "12\n",
      "June 28, 2025\n",
      "Loss spike when resuming from FSDP SHARDED_STATE_DICT checkpoint (possible optimizer-state mismatch)\n",
      "Accelerate\n",
      "1\n",
      "5\n",
      "June 28, 2025\n",
      "A new kind of way to look at ai\n",
      "Research\n",
      "9\n",
      "28\n",
      "June 27, 2025\n",
      "ONNX export failed for Qwen/Qwen3-Embedding-0.6B with \"invalid unordered_map<K, T> key\"\n",
      "Optimum\n",
      "5\n",
      "23\n",
      "June 27, 2025\n",
      "Downloads data not updating\n",
      "Hub\n",
      "5\n",
      "27\n",
      "June 28, 2025\n",
      "Example Inference API (model & code ), pls\n",
      "Beginners\n",
      "3\n",
      "14\n",
      "June 28, 2025\n",
      "In RAG systems, who's really responsible for hallucination... the model, the retriever, or the data?\n",
      "Models\n",
      "4\n",
      "44\n",
      "June 27, 2025\n",
      "Segfault during PyTorch + Transformers inference on Apple Silicon M4 (libomp.dylib crash on LayerNorm)\n",
      "Transformers\n",
      "2\n",
      "8\n",
      "June 28, 2025\n",
      "OneFormer ID/Labels for FineTuning\n",
      "Transformers\n",
      "1\n",
      "5\n",
      "June 28, 2025\n",
      "PermissionError hot-dog space example\n",
      "Spaces\n",
      "3\n",
      "13\n",
      "June 28, 2025\n",
      "How long does it take for the Zero GPU minutes to reset?\n",
      "Beginners\n",
      "1\n",
      "15\n",
      "June 27, 2025\n",
      "Dynamic Unary: A dynamic data type\n",
      "Awesome paper\n",
      "0\n",
      "8\n",
      "June 27, 2025\n",
      "Scheduling failure: unable to schedule\n",
      "Inference Endpoints on the Hub\n",
      "5\n",
      "19\n",
      "June 27, 2025\n",
      "Cloud not import module AutoImageProcessor\n",
      " Diffusers\n",
      "1\n",
      "18\n",
      "June 27, 2025\n",
      "DPO Training ruins my models conversational coherence\n",
      "Intermediate\n",
      "1\n",
      "16\n",
      "June 26, 2025\n",
      "Decoder Causal Masking [Keras]\n",
      "Intermediate\n",
      "3\n",
      "17\n",
      "June 28, 2025\n",
      "Inference result not aligned with local version of same model and revision\n",
      "Inference Endpoints on the Hub\n",
      "15\n",
      "50\n",
      "June 26, 2025\n",
      "Professional Video Making AI Tool required\n",
      "Community Calls\n",
      "0\n",
      "10\n",
      "June 27, 2025\n",
      "Unable to run space locally or duplicate\n",
      "Beginners\n",
      "8\n",
      "54\n",
      "June 26, 2025\n",
      "Where can I find wildchat-50m judgement data documentation?\n",
      "Datasets\n",
      "1\n",
      "10\n",
      "June 27, 2025\n",
      "Strange problem with huggingface-cli\n",
      "Hub\n",
      "18\n",
      "93\n",
      "June 23, 2025\n",
      "Fail to claim authorship of the paper\n",
      "Beginners\n",
      "18\n",
      "181\n",
      "June 27, 2025\n",
      "Why can't `sudo` be run in a docker container, not an isolated environment?\n",
      "Spaces\n",
      "2\n",
      "14\n",
      "June 26, 2025\n",
      "Symbolic Architecture Is the Future of AI\n",
      "Research\n",
      "8\n",
      "66\n",
      "June 27, 2025\n",
      "Prakash Hinduja Switzerland (Swiss) How do I load a pre-trained model in Hugging Face?\n",
      "Beginners\n",
      "1\n",
      "19\n",
      "June 26, 2025\n",
      "Fine-Tuning LLMs on Large Proprietary Codebases\n",
      "Models\n",
      "9\n",
      "239\n",
      "June 24, 2025\n",
      "Share an assistant\n",
      "Beginners\n",
      "4\n",
      "27\n",
      "June 25, 2025\n",
      "next page \n",
      "Home\n",
      "Categories\n",
      "Guidelines\n",
      "Terms of Service\n",
      "Privacy Policy\n",
      "Powered by\n",
      "Discourse\n",
      ", best viewed with JavaScript enabled\n",
      "\n",
      "\n",
      "\n",
      "GitHub page\n",
      "Webpage Title:\n",
      "Hugging Face  GitHub\n",
      "Webpage Contents:\n",
      "Skip to content\n",
      "Navigation Menu\n",
      "Toggle navigation\n",
      "Sign in\n",
      "Appearance settings\n",
      "huggingface\n",
      "Product\n",
      "GitHub Copilot\n",
      "Write better code with AI\n",
      "GitHub Models\n",
      "New\n",
      "Manage and compare prompts\n",
      "GitHub Advanced Security\n",
      "Find and fix vulnerabilities\n",
      "Actions\n",
      "Automate any workflow\n",
      "Codespaces\n",
      "Instant dev environments\n",
      "Issues\n",
      "Plan and track work\n",
      "Code Review\n",
      "Manage code changes\n",
      "Discussions\n",
      "Collaborate outside of code\n",
      "Code Search\n",
      "Find more, search less\n",
      "Explore\n",
      "Why GitHub\n",
      "All features\n",
      "Documentation\n",
      "GitHub Skills\n",
      "Blog\n",
      "Solutions\n",
      "By company size\n",
      "Enterprises\n",
      "Small and medium teams\n",
      "Startups\n",
      "Nonprofits\n",
      "By use case\n",
      "DevSecOps\n",
      "DevOps\n",
      "CI/CD\n",
      "View all use cases\n",
      "By industry\n",
      "Healthcare\n",
      "Financial services\n",
      "Manufacturing\n",
      "Government\n",
      "View all industries\n",
      "View all solutions\n",
      "Resources\n",
      "Topics\n",
      "AI\n",
      "DevOps\n",
      "Security\n",
      "Software Development\n",
      "View all\n",
      "Explore\n",
      "Learning Pathways\n",
      "Events & Webinars\n",
      "Ebooks & Whitepapers\n",
      "Customer Stories\n",
      "Partners\n",
      "Executive Insights\n",
      "Open Source\n",
      "GitHub Sponsors\n",
      "Fund open source developers\n",
      "The ReadME Project\n",
      "GitHub community articles\n",
      "Repositories\n",
      "Topics\n",
      "Trending\n",
      "Collections\n",
      "Enterprise\n",
      "Enterprise platform\n",
      "AI-powered developer platform\n",
      "Available add-ons\n",
      "GitHub Advanced Security\n",
      "Enterprise-grade security features\n",
      "Copilot for business\n",
      "Enterprise-grade AI features\n",
      "Premium Support\n",
      "Enterprise-grade 24/7 support\n",
      "Pricing\n",
      "Search or jump to...\n",
      "Search code, repositories, users, issues, pull requests...\n",
      "Search\n",
      "Clear\n",
      "Search syntax tips\n",
      "Provide feedback\n",
      "We read every piece of feedback, and take your input very seriously.\n",
      "Include my email address so I can be contacted\n",
      "Cancel\n",
      "Submit feedback\n",
      "Saved searches\n",
      "Use saved searches to filter your results more quickly\n",
      "Cancel\n",
      "Create saved search\n",
      "Sign in\n",
      "Sign up\n",
      "Appearance settings\n",
      "Resetting focus\n",
      "You signed in with another tab or window.\n",
      "Reload\n",
      "to refresh your session.\n",
      "You signed out in another tab or window.\n",
      "Reload\n",
      "to refresh your session.\n",
      "You switched accounts on another tab or window.\n",
      "Reload\n",
      "to refresh your session.\n",
      "Dismiss alert\n",
      "Hugging Face\n",
      "The AI community building the future.\n",
      "Verified\n",
      "We've verified that the organization\n",
      "huggingface\n",
      "controls the domain:\n",
      "huggingface.co\n",
      "Learn more about verified organizations\n",
      "Sponsor\n",
      "50.7k\n",
      "followers\n",
      "NYC + Paris\n",
      "https://huggingface.co/\n",
      "X\n",
      "@huggingface\n",
      "Overview\n",
      "Repositories\n",
      "Projects\n",
      "Packages\n",
      "People\n",
      "Sponsoring\n",
      "1\n",
      "More\n",
      "Overview\n",
      "Repositories\n",
      "Projects\n",
      "Packages\n",
      "People\n",
      "Sponsoring\n",
      "Pinned\n",
      "Loading\n",
      "transformers\n",
      "transformers\n",
      "Public\n",
      " Transformers: the model-definition framework for state-of-the-art machine learning models in text, vision, audio, and multimodal models, for both inference and training.\n",
      "Python\n",
      "146k\n",
      "29.5k\n",
      "diffusers\n",
      "diffusers\n",
      "Public\n",
      " Diffusers: State-of-the-art diffusion models for image, video, and audio generation in PyTorch and FLAX.\n",
      "Python\n",
      "29.5k\n",
      "6.1k\n",
      "datasets\n",
      "datasets\n",
      "Public\n",
      " The largest hub of ready-to-use datasets for ML models with fast, easy-to-use and efficient data manipulation tools\n",
      "Python\n",
      "20.3k\n",
      "2.9k\n",
      "peft\n",
      "peft\n",
      "Public\n",
      " PEFT: State-of-the-art Parameter-Efficient Fine-Tuning.\n",
      "Python\n",
      "18.9k\n",
      "1.9k\n",
      "accelerate\n",
      "accelerate\n",
      "Public\n",
      " A simple way to launch, train, and use PyTorch models on almost any device and distributed configuration, automatic mixed precision (including fp8), and easy-to-configure FSDP and DeepSpeed support\n",
      "Python\n",
      "8.9k\n",
      "1.1k\n",
      "optimum\n",
      "optimum\n",
      "Public\n",
      " Accelerate inference and training of  Transformers, Diffusers, TIMM and Sentence Transformers with easy to use hardware optimization tools\n",
      "Python\n",
      "3k\n",
      "553\n",
      "Repositories\n",
      "Loading\n",
      "Type\n",
      "Select type\n",
      "Forks\n",
      "Archived\n",
      "Mirrors\n",
      "Templates\n",
      "Language\n",
      "Select language\n",
      "All\n",
      "C\n",
      "C#\n",
      "C++\n",
      "Cuda\n",
      "Dockerfile\n",
      "Go\n",
      "Handlebars\n",
      "HTML\n",
      "Java\n",
      "JavaScript\n",
      "Jupyter Notebook\n",
      "Kotlin\n",
      "Lua\n",
      "MDX\n",
      "Mustache\n",
      "Nix\n",
      "Python\n",
      "Rust\n",
      "Shell\n",
      "Smarty\n",
      "Svelte\n",
      "Swift\n",
      "TypeScript\n",
      "Sort\n",
      "Select order\n",
      "Last updated\n",
      "Name\n",
      "Stars\n",
      "Showing 10 of 326 repositories\n",
      "transformers\n",
      "Public\n",
      " Transformers: the model-definition framework for state-of-the-art machine learning models in text, vision, audio, and multimodal models, for both inference and training.\n",
      "huggingface/transformerss past year of commit activity\n",
      "Python\n",
      "146,158\n",
      "Apache-2.0\n",
      "29,470\n",
      "1,067\n",
      "(2 issues need help)\n",
      "781\n",
      "Updated\n",
      "Jun 28, 2025\n",
      "lerobot\n",
      "Public\n",
      " LeRobot: Making AI for Robotics more accessible with end-to-end learning\n",
      "huggingface/lerobots past year of commit activity\n",
      "Python\n",
      "15,329\n",
      "Apache-2.0\n",
      "2,041\n",
      "286\n",
      "178\n",
      "Updated\n",
      "Jun 28, 2025\n",
      "diffusers\n",
      "Public\n",
      " Diffusers: State-of-the-art diffusion models for image, video, and audio generation in PyTorch and FLAX.\n",
      "huggingface/diffuserss past year of commit activity\n",
      "Python\n",
      "29,534\n",
      "Apache-2.0\n",
      "6,067\n",
      "509\n",
      "(11 issues need help)\n",
      "207\n",
      "Updated\n",
      "Jun 28, 2025\n",
      "inference-playground\n",
      "Public\n",
      "huggingface/inference-playgrounds past year of commit activity\n",
      "Svelte\n",
      "42\n",
      "MIT\n",
      "3\n",
      "0\n",
      "1\n",
      "Updated\n",
      "Jun 28, 2025\n",
      "lighteval\n",
      "Public\n",
      "Lighteval is your all-in-one toolkit for evaluating LLMs across multiple backends\n",
      "huggingface/lightevals past year of commit activity\n",
      "Python\n",
      "1,666\n",
      "MIT\n",
      "300\n",
      "133\n",
      "(18 issues need help)\n",
      "33\n",
      "Updated\n",
      "Jun 28, 2025\n",
      "hub-docs\n",
      "Public\n",
      "Docs of the Hugging Face Hub\n",
      "huggingface/hub-docss past year of commit activity\n",
      "Handlebars\n",
      "404\n",
      "Apache-2.0\n",
      "328\n",
      "109\n",
      "26\n",
      "Updated\n",
      "Jun 28, 2025\n",
      "diffusion-fast\n",
      "Public\n",
      "Faster generation with text-to-image diffusion models.\n",
      "huggingface/diffusion-fasts past year of commit activity\n",
      "Python\n",
      "215\n",
      "Apache-2.0\n",
      "16\n",
      "0\n",
      "0\n",
      "Updated\n",
      "Jun 28, 2025\n",
      "trl\n",
      "Public\n",
      "Train transformer language models with reinforcement learning.\n",
      "huggingface/trls past year of commit activity\n",
      "Python\n",
      "14,365\n",
      "Apache-2.0\n",
      "1,995\n",
      "410\n",
      "84\n",
      "Updated\n",
      "Jun 28, 2025\n",
      "flux-fast\n",
      "Public\n",
      "Making Flux go brrr on GPUs.\n",
      "huggingface/flux-fasts past year of commit activity\n",
      "Python\n",
      "24\n",
      "2\n",
      "1\n",
      "1\n",
      "Updated\n",
      "Jun 28, 2025\n",
      "huggingface.js\n",
      "Public\n",
      "Use Hugging Face with JavaScript\n",
      "huggingface/huggingface.jss past year of commit activity\n",
      "TypeScript\n",
      "2,155\n",
      "MIT\n",
      "443\n",
      "105\n",
      "(5 issues need help)\n",
      "59\n",
      "Updated\n",
      "Jun 28, 2025\n",
      "View all repositories\n",
      "People\n",
      "View all\n",
      "Sponsoring\n",
      "Top languages\n",
      "Python\n",
      "Jupyter Notebook\n",
      "Rust\n",
      "TypeScript\n",
      "JavaScript\n",
      "Most used topics\n",
      "pytorch\n",
      "machine-learning\n",
      "nlp\n",
      "transformers\n",
      "deep-learning\n",
      "GitHub Sponsor\n",
      "Footer\n",
      " 2025 GitHub,Inc.\n",
      "Footer navigation\n",
      "Terms\n",
      "Privacy\n",
      "Security\n",
      "Status\n",
      "Docs\n",
      "Contact\n",
      "Manage cookies\n",
      "Do not share my personal information\n",
      "You cant perform that action at this time.\n",
      "\n",
      "\n",
      "\n",
      "Twitter page\n",
      "Webpage Title:\n",
      "No title found\n",
      "Webpage Contents:\n",
      "JavaScript is not available.\n",
      "Weve detected that JavaScript is disabled in this browser. Please enable JavaScript or switch to a supported browser to continue using x.com. You can see a list of supported browsers in our Help Center.\n",
      "Help Center\n",
      "Terms of Service\n",
      "Privacy Policy\n",
      "Cookie Policy\n",
      "Imprint\n",
      "Ads info\n",
      " 2025 X Corp.\n",
      "Something went wrong, but dont fret  lets give it another shot.\n",
      "Try again\n",
      "Some privacy related extensions may cause issues on x.com. Please disable them and try again.\n",
      "\n",
      "\n",
      "\n",
      "LinkedIn page\n",
      "Webpage Title:\n",
      "Hugging Face | LinkedIn\n",
      "Webpage Contents:\n",
      "Skip to main content\n",
      "LinkedIn\n",
      "Articles\n",
      "People\n",
      "Learning\n",
      "Jobs\n",
      "Games\n",
      "Get the app\n",
      "Join now\n",
      "Sign in\n",
      "Hugging Face\n",
      "Software Development\n",
      "The AI community building the future.\n",
      "See jobs\n",
      "Follow\n",
      "Discover all 564 employees\n",
      "Report this company\n",
      "About us\n",
      "The AI community building the future.\n",
      "Website\n",
      "https://huggingface.co\n",
      "External link for Hugging Face\n",
      "Industry\n",
      "Software Development\n",
      "Company size\n",
      "51-200 employees\n",
      "Type\n",
      "Privately Held\n",
      "Founded\n",
      "2016\n",
      "Specialties\n",
      "machine learning, natural language processing, and deep learning\n",
      "Products\n",
      "Hugging Face\n",
      "Hugging Face\n",
      "Natural Language Processing (NLP) Software\n",
      "Were on a journey to solve and democratize artificial intelligence through natural language.\n",
      "Locations\n",
      "Primary\n",
      "Get directions\n",
      "Paris, FR\n",
      "Get directions\n",
      "Employees at Hugging Face\n",
      "Ludovic Huraux\n",
      "Rajat Arya\n",
      "Tech Lead & Software Engineer @ HF | prev: co-founder XetHub, Apple, Turi, AWS, Microsoft\n",
      "Jeff Boudier\n",
      "Product + Growth at Hugging Face\n",
      "Terrence Rohan\n",
      "Seed Investor\n",
      "See all employees\n",
      "Updates\n",
      "Hugging Face\n",
      "reposted this\n",
      "Sayak Paul\n",
      "ML @ Hugging Face \n",
      "1d\n",
      "Report this post\n",
      "Diffusion transformers (DiT) are my favorite thing to play around with. It's still crazy to me how simple changes to the original ViT architecture can enable so many use cases \n",
      "\n",
      "I have put together a presentation, going over my favorite DiT architectures in the image generation space:\n",
      "\n",
      "1. UNets for image generation and why we need DiTs\n",
      "2. The OG DiT architecture (class-conditional)\n",
      "3. Enabling text-to-image generation in the OG DiT\n",
      "4. MMDiTs\n",
      "5. Other friends (AuraFlow, DiT-Air, FuseDiT, OmniGen, etc.)\n",
      "\n",
      "Thanks to\n",
      "Steven Feng\n",
      ", I had the honor of presenting this at CS25, Stanford. Quite the moment for me, honestly. \n",
      "\n",
      "Find the recording below:\n",
      "https://lnkd.in/gQRrDEKG\n",
      "more\n",
      "Stanford CS25: V5 I Transformers in Diffusion Models for Image Generation and Beyond\n",
      "https://www.youtube.com/\n",
      "702\n",
      "21 Comments\n",
      "Like\n",
      "Comment\n",
      "Share\n",
      "Hugging Face\n",
      "reposted this\n",
      "Gradio\n",
      "66,347 followers\n",
      "2d\n",
      "Report this post\n",
      "Today, we are excited to launch , a lightweight experiment tracking and visualization library  written in <1,000 lines of Python  that is completely open-source, 100% free to use, locally or hosted.\n",
      "\n",
      "Why did we create an experiment tracking library when others exist? 3 reasons:\n",
      "\n",
      " Extensibility: libraries for experiment tracking often are not extensible: if you want to want or add a feature, track something completely new, or change the UI, you can't easily do it since the hosted piece is closed-source or at least not written in Python. Trackio is not a walled garden  fork it and change the Python code however you need and it'll work fine.\n",
      "\n",
      " Local-first: You shouldn't need an account just to track and visualize metrics! We wanted to give ML practitioners a local-first option that allowed them to  track metrics privately. Of course, If you want to persist the logs or share the dashboard with others, you have the option to do that through Hugging Face datasets/Spaces with a single line of code.\n",
      "\n",
      " FREE: did we mention that Trackio is free to use, even for hosted dashboards?\n",
      "\n",
      "It also comes with a familiar API so you can start using it immediately!\n",
      "\n",
      "Try it today:   \n",
      "\n",
      "Or star the repo:\n",
      "https://lnkd.in/gn6zXUUT\n",
      "more\n",
      "291\n",
      "9 Comments\n",
      "Like\n",
      "Comment\n",
      "Share\n",
      "Hugging Face\n",
      "reposted this\n",
      "Daniel Vila Suero\n",
      "Building data tools @ Hugging Face \n",
      "2d\n",
      "Report this post\n",
      " The fastest, most fun way to build image and text datasets  \n",
      "\n",
      "\n",
      "It's like Excel for unstructured data, with access to +40K open-source models on\n",
      "Hugging Face\n",
      ". \n",
      "\n",
      "Try it out:\n",
      "https://lnkd.in/dVu2f2SB\n",
      "more\n",
      "80\n",
      "5 Comments\n",
      "Like\n",
      "Comment\n",
      "Share\n",
      "Hugging Face\n",
      "reposted this\n",
      "Amlie Viallet\n",
      "Crafting interactions with data  Hugging Face | Building 'Sheets' the AI-powered spreadsheet\n",
      "2d\n",
      "Report this post\n",
      " Heres a fun educational video I made to show how Sheets and AI can upgrade your structured content.\n",
      "\n",
      "Better tables and clearer messages with just a little help from AI!\n",
      "\n",
      "Please try it and let me know what you think, especially in the context of your use cases!\n",
      "https://lnkd.in/dxuWMTrt\n",
      "more\n",
      "49\n",
      "3 Comments\n",
      "Like\n",
      "Comment\n",
      "Share\n",
      "Hugging Face\n",
      "reposted this\n",
      "Nathan HABIB\n",
      "ML Enginneer at Hugging Face\n",
      "\n",
      "X: @nathanhabib1011\n",
      "3d\n",
      "Report this post\n",
      "Evaluation was just made easier  \n",
      "\n",
      "We merged a huge refacto of lighteval making easier to add:\n",
      " Multiturn tasks\n",
      " Multimodal tasks\n",
      " Plus unified logs for thorough benchmark analysis\n",
      "\n",
      "Benchmarks guys, what evals would you like to see added ?\n",
      "https://lnkd.in/emZNQWUd\n",
      "GitHub - huggingface/lighteval: Lighteval is your all-in-one toolkit for evaluating LLMs across multiple backends\n",
      "github.com\n",
      "63\n",
      "7 Comments\n",
      "Like\n",
      "Comment\n",
      "Share\n",
      "Hugging Face\n",
      "reposted this\n",
      "Lysandre Debut\n",
      "COSO - Chief Open Source Officer at Hugging Face\n",
      "3d\n",
      "Report this post\n",
      "\"The great unbloating\" of transformers continues.\n",
      "\n",
      "Over the past few weeks, 10+ PRs were merged, aiming to simplify code across the library.\n",
      "\n",
      "This brought in refactors for Attention, the Cache, a new linter. We're improving type hints everywhere, and are checking type checkers.\n",
      "\n",
      "We take the following approach: modeling files should be explicit. Abstract, model-agnostic utils, should not be part of them.\n",
      "\n",
      "On top of removing a lot of bloat from modeling, this enables us to ship much better utilities common to all models. This leads to significant diffs like the image below.\n",
      "\n",
      "This is the beginning of a longer effort simplifying the library, laying the ground for a v5 release with a simpler, optimized toolkit.\n",
      "\n",
      "Kudos to\n",
      "Arthur Zucker\n",
      ",\n",
      "Raushan Turganbay\n",
      ",\n",
      "Joo Gante\n",
      ",\n",
      "Pavel Iakubovskii\n",
      ",\n",
      "Pablo Montalvo\n",
      ",\n",
      "Cyril Vallez\n",
      ", Matt, Anton, and many community members making this possible.\n",
      "854\n",
      "15 Comments\n",
      "Like\n",
      "Comment\n",
      "Share\n",
      "Hugging Face\n",
      "reposted this\n",
      "William James Mattingly, Ph.D.\n",
      "Cultural Heritage Data Scientist at Yale University  NLP Expert  Digital Humanities  Digital Nomad\n",
      "3d\n",
      "Report this post\n",
      "Have high quality data sitting on Transkribus? Want to make it available on\n",
      "Hugging Face\n",
      "with a single command line? Introducing Transkribus-HF which allows you to take a Transkribus export zip and make it into a HF dataset! It can parse pages, regions, lines, or windows!\n",
      "\n",
      "Repo:\n",
      "https://lnkd.in/ePFTKf55\n",
      "26\n",
      "2 Comments\n",
      "Like\n",
      "Comment\n",
      "Share\n",
      "Hugging Face\n",
      "reposted this\n",
      "Daniel van Strien\n",
      "Machine Learning Librarian at \n",
      "3d\n",
      "Report this post\n",
      " OCR Time Machine: Compare Traditional OCR vs \"Modern\" VLM-based OCR\n",
      "\n",
      "The past few months have seen a surge of new OCR model releases  many powered by Vision-Language Models (VLMs) and generating Markdown-style outputs.\n",
      "\n",
      "At the same time, libraries and archives hold vast collections of OCR generated using traditional software, often in XML formats like ALTO or PAGE. The quality of that OCR? Varies wildly. Some of it is pretty good. Some of it is comwlkfklfy unreadable!!\n",
      "\n",
      "To help people explore how these new models perform on historical material, Ive built a\n",
      "Hugging Face\n",
      "Space that lets you compare traditional XML-based OCR outputs with results from modern VLM-based OCR, side by side.\n",
      "\n",
      " What it does\n",
      "\n",
      "- Upload a historical document image and (optionally) its existing OCR XML\n",
      "- Run OCR using a modern VLM (RolmOCR or Nanonets-OCR-s)\n",
      "- Compare the two outputs side by side\n",
      "- Download results for further use or analysis\n",
      "\n",
      " Try it here:\n",
      "https://lnkd.in/eq2U2F_q\n",
      " Built for\n",
      "\n",
      "- GLAM institutions exploring modern OCR workflows\n",
      "- Digital humanists working with legacy OCR data\n",
      "- Developers and ML researchers testing VLM performance on historical or layout-heavy documents\n",
      "\n",
      "Ive already found cases where traditional OCR outperforms the newer models  OCR is definitely not a solved problem!\n",
      "\n",
      "If youve worked with ALTO, PAGE, or other XML-heavy OCR formats, Id love to hear how this performs on your data!\n",
      "OCR Time Machine - a Hugging Face Space by davanstrien\n",
      "huggingface.co\n",
      "233\n",
      "11 Comments\n",
      "Like\n",
      "Comment\n",
      "Share\n",
      "Hugging Face\n",
      "reposted this\n",
      "Gradio\n",
      "66,347 followers\n",
      "4d\n",
      "Edited\n",
      "Report this post\n",
      "\n",
      "Mistral AI\n",
      "Choice Award of $2000 worth of API Credits goes to OpenSorus! \n",
      "\n",
      "This GitHub agent automates issue triage for open-source projects. It reads GitHub issues, analyzes codebases using semantic search, and posts contextually relevant responses - like having a 24/7 developer support assistant.\n",
      "\n",
      "Built with\n",
      "Gradio\n",
      "and\n",
      "Mistral AI\n",
      "'s Devstral & Codestral models. Perfect solution for overwhelmed OSS maintainers!  \n",
      "\n",
      "$2000 API credits well deserved  Check out the agentic app here:\n",
      "https://lnkd.in/gfKeRt7W\n",
      "105\n",
      "8 Comments\n",
      "Like\n",
      "Comment\n",
      "Share\n",
      "Hugging Face\n",
      "reposted this\n",
      "Gradio\n",
      "66,347 followers\n",
      "5d\n",
      "Edited\n",
      "Report this post\n",
      " LLAMAINDEX CHOICE AWARD  Cash Prize: $1,000 \n",
      "NASA Space Explorer wins\n",
      "LlamaIndex\n",
      "'s choice award at the\n",
      "Gradio\n",
      "Agents & MCP hackathon! \n",
      "\n",
      "What they built: LlamaIndex-powered Agentic app that delivers NASA's live space data via custom MCP servers with 15 specialized NASA tools\n",
      "\n",
      "\n",
      "NASA - National Aeronautics and Space Administration\n",
      "- Space Explorer \n",
      " Play with the winning app here:\n",
      "https://lnkd.in/gEJeB2vX\n",
      "  Thanks to the brilliant LLamaIndex team of\n",
      "Tuana elik\n",
      ",\n",
      "Logan Markewich\n",
      ", and\n",
      "Laurie Voss\n",
      ", for making this collaboration a HUGE success!\n",
      "54\n",
      "5 Comments\n",
      "Like\n",
      "Comment\n",
      "Share\n",
      "Join now to see what you are missing\n",
      "Find people you know at Hugging Face\n",
      "Browse recommended jobs for you\n",
      "View all updates, news, and articles\n",
      "Join now\n",
      "Similar pages\n",
      "Anthropic\n",
      "Research Services\n",
      "Perplexity\n",
      "Software Development\n",
      "San Francisco, California\n",
      "Mistral AI\n",
      "Technology, Information and Internet\n",
      "Paris, France\n",
      "OpenAI\n",
      "Research Services\n",
      "San Francisco, CA\n",
      "LangChain\n",
      "Technology, Information and Internet\n",
      "Generative AI\n",
      "Technology, Information and Internet\n",
      "DeepLearning.AI\n",
      "Software Development\n",
      "Palo Alto, California\n",
      "Google DeepMind\n",
      "Research Services\n",
      "London, London\n",
      "Cohere\n",
      "Software Development\n",
      "Toronto, Ontario\n",
      "LlamaIndex\n",
      "Technology, Information and Internet\n",
      "San Francisco, California\n",
      "Show more similar pages\n",
      "Show fewer similar pages\n",
      "Browse jobs\n",
      "Engineer jobs\n",
      "555,845 open jobs\n",
      "Machine Learning Engineer jobs\n",
      "148,937 open jobs\n",
      "Scientist jobs\n",
      "48,969 open jobs\n",
      "Software Engineer jobs\n",
      "300,699 open jobs\n",
      "Analyst jobs\n",
      "694,057 open jobs\n",
      "Intern jobs\n",
      "71,196 open jobs\n",
      "Developer jobs\n",
      "258,935 open jobs\n",
      "Manager jobs\n",
      "1,880,925 open jobs\n",
      "Product Manager jobs\n",
      "199,941 open jobs\n",
      "Director jobs\n",
      "1,220,357 open jobs\n",
      "Python Developer jobs\n",
      "46,642 open jobs\n",
      "Data Scientist jobs\n",
      "264,158 open jobs\n",
      "Data Analyst jobs\n",
      "329,009 open jobs\n",
      "Senior Software Engineer jobs\n",
      "78,145 open jobs\n",
      "Project Manager jobs\n",
      "253,048 open jobs\n",
      "Researcher jobs\n",
      "195,654 open jobs\n",
      "Associate jobs\n",
      "1,091,945 open jobs\n",
      "Data Engineer jobs\n",
      "192,126 open jobs\n",
      "Vice President jobs\n",
      "235,270 open jobs\n",
      "Specialist jobs\n",
      "768,666 open jobs\n",
      "Show more jobs like this\n",
      "Show fewer jobs like this\n",
      "Funding\n",
      "Hugging Face\n",
      "8 total rounds\n",
      "Last Round\n",
      "Series unknown\n",
      "Sep 1, 2024\n",
      "External Crunchbase Link for last round of funding\n",
      "See more info on\n",
      "crunchbase\n",
      "More searches\n",
      "More searches\n",
      "Engineer jobs\n",
      "Scientist jobs\n",
      "Machine Learning Engineer jobs\n",
      "Software Engineer jobs\n",
      "Intern jobs\n",
      "Developer jobs\n",
      "Analyst jobs\n",
      "Manager jobs\n",
      "Senior Software Engineer jobs\n",
      "Data Scientist jobs\n",
      "Researcher jobs\n",
      "Product Manager jobs\n",
      "Director jobs\n",
      "Associate jobs\n",
      "Intelligence Specialist jobs\n",
      "Data Analyst jobs\n",
      "Data Science Specialist jobs\n",
      "Python Developer jobs\n",
      "Quantitative Analyst jobs\n",
      "Project Manager jobs\n",
      "Account Executive jobs\n",
      "Specialist jobs\n",
      "Data Engineer jobs\n",
      "Designer jobs\n",
      "Quantitative Researcher jobs\n",
      "Consultant jobs\n",
      "Solutions Architect jobs\n",
      "Vice President jobs\n",
      "User Experience Designer jobs\n",
      "Head jobs\n",
      "Full Stack Engineer jobs\n",
      "Engineering Manager jobs\n",
      "Software Engineer Intern jobs\n",
      "Junior Software Engineer jobs\n",
      "Software Intern jobs\n",
      "Product Designer jobs\n",
      "Solutions Engineer jobs\n",
      "Staff Software Engineer jobs\n",
      "Program Manager jobs\n",
      "Senior Scientist jobs\n",
      "Writer jobs\n",
      "Research Intern jobs\n",
      "Senior Product Manager jobs\n",
      "Summer Intern jobs\n",
      "Account Manager jobs\n",
      "Recruiter jobs\n",
      "Lead jobs\n",
      "Research Engineer jobs\n",
      "Computer Science Intern jobs\n",
      "Platform Engineer jobs\n",
      "Junior Developer jobs\n",
      "Android Developer jobs\n",
      "User Experience Researcher jobs\n",
      "Java Software Engineer jobs\n",
      "Site Reliability Engineer jobs\n",
      "Graduate jobs\n",
      "Software Engineering Manager jobs\n",
      "Representative jobs\n",
      "Business Development Specialist jobs\n",
      "Computer Engineer jobs\n",
      "LinkedIn\n",
      " 2025\n",
      "About\n",
      "Accessibility\n",
      "User Agreement\n",
      "Privacy Policy\n",
      "Your California Privacy Choices\n",
      "Cookie Policy\n",
      "Copyright Policy\n",
      "Brand Policy\n",
      "Guest Controls\n",
      "Community Guidelines\n",
      " (Arabic)\n",
      " (Bangla)\n",
      "etina (Czech)\n",
      "Dansk (Danish)\n",
      "Deutsch (German)\n",
      " (Greek)\n",
      "English (English)\n",
      "Espaol (Spanish)\n",
      " (Persian)\n",
      "Suomi (Finnish)\n",
      "Franais (French)\n",
      " (Hindi)\n",
      "Magyar (Hungarian)\n",
      "Bahasa Indonesia (Indonesian)\n",
      "Italiano (Italian)\n",
      " (Hebrew)\n",
      " (Japanese)\n",
      " (Korean)\n",
      " (Marathi)\n",
      "Bahasa Malaysia (Malay)\n",
      "Nederlands (Dutch)\n",
      "Norsk (Norwegian)\n",
      " (Punjabi)\n",
      "Polski (Polish)\n",
      "Portugus (Portuguese)\n",
      "Romn (Romanian)\n",
      " (Russian)\n",
      "Svenska (Swedish)\n",
      " (Telugu)\n",
      " (Thai)\n",
      "Tagalog (Tagalog)\n",
      "Trke (Turkish)\n",
      " (Ukrainian)\n",
      "Ting Vit (Vietnamese)\n",
      " (Chinese (Simplified))\n",
      " (Chinese (Traditional))\n",
      "Language\n",
      "Agree & Join LinkedIn\n",
      "By clicking Continue to join or sign in, you agree to LinkedIns\n",
      "User Agreement\n",
      ",\n",
      "Privacy Policy\n",
      ", and\n",
      "Cookie Policy\n",
      ".\n",
      "Sign in to see who you already know at Hugging Face\n",
      "Sign in\n",
      "Welcome back\n",
      "Email or phone\n",
      "Password\n",
      "Show\n",
      "Forgot password?\n",
      "Sign in\n",
      "or\n",
      "By clicking Continue to join or sign in, you agree to LinkedIns\n",
      "User Agreement\n",
      ",\n",
      "Privacy Policy\n",
      ", and\n",
      "Cookie Policy\n",
      ".\n",
      "New to LinkedIn?\n",
      "Join now\n",
      "or\n",
      "New to LinkedIn?\n",
      "Join now\n",
      "By clicking Continue to join or sign in, you agree to LinkedIns\n",
      "User Agreement\n",
      ",\n",
      "Privacy Policy\n",
      ", and\n",
      "Cookie Policy\n",
      ".\n",
      "LinkedIn\n",
      "LinkedIn is better on the app\n",
      "Dont have the app? Get it in the Microsoft Store.\n",
      "Open the app\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(get_all_details(\"https://huggingface.co\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b863a55-f86c-4e3f-8a79-94e24c1a8cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are an assistant that analyzes the contents of several relevant pages from a company website \\\n",
    "and creates a short brochure about the company for prospective customers, investors and recruits. Respond in markdown.\\\n",
    "Include details of company culture, customers and careers/jobs if you have the information.\"\n",
    "\n",
    "# Or uncomment the lines below for a more humorous brochure - this demonstrates how easy it is to incorporate 'tone':\n",
    "\n",
    "# system_prompt = \"You are an assistant that analyzes the contents of several relevant pages from a company website \\\n",
    "# and creates a short humorous, entertaining, jokey brochure about the company for prospective customers, investors and recruits. Respond in markdown.\\\n",
    "# Include details of company culture, customers and careers/jobs if you have the information.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ab83d92-d36b-4ce0-8bcc-5bb4c2f8ff23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_brochure_user_prompt(company_name, url):\n",
    "    user_prompt = f\"You are looking at a company called: {company_name}\\n\"\n",
    "    user_prompt += f\"Here are the contents of its landing page and other relevant pages; use this information to build a short brochure of the company in markdown.\\n\"\n",
    "    user_prompt += get_all_details(url)\n",
    "    user_prompt = user_prompt[:5_000] # Truncate if more than 5,000 characters\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cd909e0b-1312-4ce2-a553-821e795d7572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found links: {'links': [{'type': 'about page', 'url': 'https://huggingface.co/huggingface'}, {'type': 'careers page', 'url': 'https://apply.workable.com/huggingface/'}, {'type': 'enterprise page', 'url': 'https://huggingface.co/enterprise'}, {'type': 'pricing page', 'url': 'https://huggingface.co/pricing'}, {'type': 'blog page', 'url': 'https://huggingface.co/blog'}, {'type': 'discuss page', 'url': 'https://discuss.huggingface.co'}, {'type': 'GitHub page', 'url': 'https://github.com/huggingface'}, {'type': 'Twitter page', 'url': 'https://twitter.com/huggingface'}, {'type': 'LinkedIn page', 'url': 'https://www.linkedin.com/company/huggingface/'}]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'You are looking at a company called: HuggingFace\\nHere are the contents of its landing page and other relevant pages; use this information to build a short brochure of the company in markdown.\\nLanding page:\\nWebpage Title:\\nHugging Face  The AI community building the future.\\nWebpage Contents:\\nHugging Face\\nModels\\nDatasets\\nSpaces\\nCommunity\\nDocs\\nEnterprise\\nPricing\\nLog In\\nSign Up\\nThe AI community building the future.\\nThe platform where the machine learning community collaborates on models, datasets, and applications.\\nExplore AI Apps\\nor\\nBrowse 1M+ models\\nTrending on\\nthis week\\nModels\\nblack-forest-labs/FLUX.1-Kontext-dev\\nUpdated\\nabout 18 hours ago\\n\\n12.9k\\n\\n826\\ntencent/Hunyuan-A13B-Instruct\\nUpdated\\nabout 12 hours ago\\n\\n452\\ngoogle/magenta-realtime\\nUpdated\\n5 days ago\\n\\n390\\nnanonets/Nanonets-OCR-s\\nUpdated\\n8 days ago\\n\\n202k\\n\\n1.22k\\ngoogle/gemma-3n-E4B-it\\nUpdated\\n1 day ago\\n\\n5.55k\\n\\n222\\nBrowse 1M+ models\\nSpaces\\nRunning\\n8.75k\\n8.75k\\nDeepSite v2\\n\\nGenerate any application with DeepSeek\\nRunning\\n865\\n865\\nSparc3D\\n\\nNext-Gen High-Resolution 3D Model Generation\\nRunning\\non\\nZero\\n274\\n274\\nOmniGen2\\n\\nOmniGen2: Unified Image Understanding and Generation.\\nRunning\\non\\nZero\\n522\\n522\\nHunyuan3D-2.1\\n\\nImage-to-3D Generation\\nRunning\\non\\nZero\\nMCP\\n187\\n187\\nFLUX.1 Kontext\\n\\nKontext image editing on FLUX[dev]\\nBrowse 400k+ applications\\nDatasets\\nfka/awesome-chatgpt-prompts\\nUpdated\\nJan 6\\n\\n22.9k\\n\\n8.06k\\ninstitutional/institutional-books-1.0\\nUpdated\\n12 days ago\\n\\n38.2k\\n\\n199\\nEssentialAI/essential-web-v1.0\\nUpdated\\n6 days ago\\n\\n75.5k\\n\\n162\\nfacebook/seamless-interaction\\nUpdated\\nabout 24 hours ago\\n\\n1\\n\\n35\\nFreedomIntelligence/ShareGPT-4o-Image\\nUpdated\\nabout 13 hours ago\\n\\n75\\n\\n32\\nBrowse 250k+ datasets\\nThe Home of Machine Learning\\nCreate, discover and collaborate on ML better.\\nThe collaboration platform\\nHost and collaborate on unlimited public models, datasets and applications.\\nMove faster\\nWith the HF Open source stack.\\nExplore all modalities\\nText, image, video, audio or even 3D.\\nBuild your portfolio\\nShare your work with the world and build your ML profile.\\nSign Up\\nAccelerate your ML\\nWe provide paid Compute and Enterprise solutions.\\nCompute\\nDeploy on optimized\\nInference Endpoints\\nor update your\\nSpaces applications\\nto a GPU in a few clicks.\\nView pricing\\nStarting at $0.60/hour for GPU\\nEnterprise\\nGive your team the most advanced platform to build AI with enterprise-grade security, access controls and\\n\\t\\t\\tdedicated support.\\nGetting started\\nStarting at $20/user/month\\nSingle Sign-On\\nRegions\\nPriority Support\\nAudit Logs\\nResource Groups\\nPrivate Datasets Viewer\\nMore than 50,000 organizations are using Hugging Face\\nAi2\\nEnterprise\\nnon-profit\\n\\n766 models\\n\\n3.5k followers\\nAI at Meta\\nEnterprise\\ncompany\\n\\n2.17k models\\n\\n6.61k followers\\nAmazon\\ncompany\\n\\n20 models\\n\\n3.26k followers\\nGoogle\\ncompany\\n\\n1.01k models\\n\\n17.7k followers\\nIntel\\ncompany\\n\\n207 models\\n\\n2.68k followers\\nMicrosoft\\ncompany\\n\\n395 models\\n\\n13.2k followers\\nGrammarly\\nTeam\\ncompany\\n\\n10 models\\n\\n166 followers\\nWriter\\nEnterprise\\ncompany\\n\\n21 models\\n\\n302 followers\\nOur Open Source\\nWe are building the foundation of ML tooling with the community.\\nTransformers\\n146,158\\nState-of-the-art ML for PyTorch, TensorFlow, JAX\\nDiffusers\\n29,534\\nState-of-the-art Diffusion models in PyTorch\\nSafetensors\\n3,329\\nSafe way to store/distribute neural network weights\\nHub Python Library\\n2,721\\nPython client to interact with the Hugging Face Hub\\nTokenizers\\n9,847\\nFast tokenizers optimized for research & production\\nTRL\\n14,365\\nTrain transformers LMs with reinforcement learning\\nTransformers.js\\n13,912\\nState-of-the-art ML running directly in your browser\\nsmolagents\\n20,661\\nSmol library to build great agents in Python\\nPEFT\\n18,875\\nParameter-efficient finetuning for large language models\\nDatasets\\n20,310\\nAccess & share datasets for any ML tasks\\nText Generation Inference\\n10,261\\nServe language models with TGI optimized toolkit\\nAccelerate\\n8,876\\nTrain PyTorch models with multi-GPU, TPU, mixed precision\\nSystem theme\\nWebsite\\nModels\\nDatasets\\nSpaces\\nChangelog\\nInference Endpoints\\nHuggingChat\\nCompany\\nAbout\\nBrand assets\\nTerms of service\\nPrivacy\\nJobs\\nPress\\nResources\\nLearn\\nDocumentation\\nBlog\\nForum\\nService Status\\nSocial\\nGitHub\\nTwitter\\nLinkedIn\\nDiscord\\n\\n\\n\\nabout page\\nWebpage Title:\\nhuggingface (Hugging Face)\\nWebpage Contents:\\nHugging Face\\nModels\\nDatasets\\nSpaces\\nCommunity\\nDocs\\nEnterprise\\nPricing\\nLog In\\nSign Up\\nHugging Face\\nEnterprise\\ncompany\\nVerified\\nhttps://huggingface.co\\nhuggingface\\nhuggingface\\nActivity Feed\\nFollow\\n45,797\\nAI & ML interests\\nThe AI community building the future.\\nRecent Activity\\nlysandre\\nupdated\\na dataset\\n1 day ago\\nhuggingface/transformers-metadata\\nthomwolf\\nauthored\\na paper\\n1 day ago\\nFineWeb2: One Pipeline to Scale Them All -- Adapting Pre-Training Data\\n  Processing to Every Language\\nguipenedo\\nauthored\\na paper\\n1 day ago\\nFineWeb2: One Pipeline to Scale Them All -- Adapting Pre-Training Data\\n  Processing to Every Language\\nView all activity\\nArticles\\nYay! Organizations can now publish blog Articles\\nJan 20\\n\\n46\\nTeam members\\n213\\n+179\\n+166\\n+145\\n+135\\n+115\\nOrganizat'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_brochure_user_prompt(\"HuggingFace\", \"https://huggingface.co\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e44de579-4a1a-4e6a-a510-20ea3e4b8d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_brochure(company_name, url):\n",
    "    response = openai.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": get_brochure_user_prompt(company_name, url)}\n",
    "          ],\n",
    "    )\n",
    "    result = response.choices[0].message.content\n",
    "    display(Markdown(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e093444a-9407-42ae-924a-145730591a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found links: {'links': [{'type': 'about page', 'url': 'https://huggingface.co/huggingface'}, {'type': 'careers page', 'url': 'https://apply.workable.com/huggingface/'}, {'type': 'enterprise page', 'url': 'https://huggingface.co/enterprise'}, {'type': 'pricing page', 'url': 'https://huggingface.co/pricing'}, {'type': 'blog page', 'url': 'https://huggingface.co/blog'}, {'type': 'docs page', 'url': 'https://huggingface.co/docs'}]}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```markdown\n",
       "# Hugging Face Brochure\n",
       "\n",
       "## Welcome to Hugging Face\n",
       "**The AI Community Building the Future**\n",
       "\n",
       "At Hugging Face, we host a collaborative platform that empowers the machine learning (ML) community to innovate and create. With over 1 million models and 250,000 datasets, our mission is to push the boundaries of artificial intelligence through shared knowledge and resources.\n",
       "\n",
       "---\n",
       "\n",
       "## Our Offerings\n",
       "- **Models**: Explore a vast array of machine learning models, from the latest advancements to established classics.\n",
       "- **Datasets**: Access an extensive collection of datasets tailored for various ML tasks.\n",
       "- **Spaces**: Engage with applications and tools developed by the community.\n",
       "- **Enterprise Solutions**: We offer compute and enterprise-grade infrastructure with advanced security features for organizations looking to scale their AI projects.\n",
       "\n",
       "---\n",
       "\n",
       "## Our Customers\n",
       "Hugging Face is trusted by more than 50,000 organizations, including industry leaders like:\n",
       "- **Meta**\n",
       "- **Google**\n",
       "- **Microsoft**\n",
       "- **Amazon**\n",
       "- **Intel**\n",
       "\n",
       "Our client base spans various sectors, including non-profit organizations and tech companies, showcasing the versatility and adaptability of our platform.\n",
       "\n",
       "---\n",
       "\n",
       "## Company Culture\n",
       "We pride ourselves on fostering a diverse and inclusive company culture that nurtures innovation and collaboration. Our community-driven approach emphasizes transparency and participation, allowing individuals from all walks of life to contribute and grow. Our team comprises passionate individuals dedicated to advancing the field of AI and ML.\n",
       "\n",
       "### Community Engagement\n",
       "We consistently engage with our community through forums, blogs, and social media platforms, prioritizing open communication and shared learning.\n",
       "\n",
       "---\n",
       "\n",
       "## Careers at Hugging Face\n",
       "We are always looking for smart, driven individuals to join our growing team. At Hugging Face, career possibilities are endless as we constantly innovate and expand our offerings. We value creativity, ambition, and a collaborative spirit. If you're interested in building the future of AI together, explore our [career opportunities](https://huggingface.co/jobs).\n",
       "\n",
       "---\n",
       "\n",
       "## Join Us\n",
       "If you are ready to contribute to a vibrant community that is shaping the future of technology, whether as a customer, investor, or potential team member, Hugging Face is the place for you. \n",
       "\n",
       "**Explore our platform today!**\n",
       "\n",
       "[Visit Hugging Face](https://huggingface.co)\n",
       "\n",
       "---\n",
       "\n",
       "_Making machine learning accessible for all._\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "create_brochure(\"HuggingFace\", \"https://huggingface.co\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61eaaab7-0b47-4b29-82d4-75d474ad8d18",
   "metadata": {},
   "source": [
    "## Finally - a minor improvement\n",
    "\n",
    "With a small adjustment, we can change this so that the results stream back from OpenAI,\n",
    "with the familiar typewriter animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "51db0e49-f261-4137-aabe-92dd601f7725",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_brochure(company_name, url):\n",
    "    stream = openai.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": get_brochure_user_prompt(company_name, url)}\n",
    "          ],\n",
    "        stream=True\n",
    "    )\n",
    "    \n",
    "    response = \"\"\n",
    "    display_handle = display(Markdown(\"\"), display_id=True)\n",
    "    for chunk in stream:\n",
    "        response += chunk.choices[0].delta.content or ''\n",
    "        response = response.replace(\"```\",\"\").replace(\"markdown\", \"\")\n",
    "        update_display(Markdown(response), display_id=display_handle.display_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "56bf0ae3-ee9d-4a72-9cd6-edcac67ceb6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found links: {'links': [{'type': 'about page', 'url': 'https://huggingface.co/huggingface'}, {'type': 'careers page', 'url': 'https://apply.workable.com/huggingface/'}, {'type': 'enterprise page', 'url': 'https://huggingface.co/enterprise'}, {'type': 'pricing page', 'url': 'https://huggingface.co/pricing'}, {'type': 'blog page', 'url': 'https://huggingface.co/blog'}, {'type': 'community page', 'url': 'https://discuss.huggingface.co'}, {'type': 'status page', 'url': 'https://status.huggingface.co'}, {'type': 'GitHub page', 'url': 'https://github.com/huggingface'}, {'type': 'Twitter page', 'url': 'https://twitter.com/huggingface'}, {'type': 'LinkedIn page', 'url': 'https://www.linkedin.com/company/huggingface/'}]}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "# Hugging Face Company Brochure\n",
       "\n",
       "---\n",
       "\n",
       "## **About Us**\n",
       "Hugging Face is a pioneering company in the AI and machine learning community. Our mission is to build the future of AI collaboration by providing a comprehensive platform that connects researchers, developers, and organizations worldwide. From models to datasets and applications, we facilitate discovery and innovation in machine learning, making advanced technology accessible for all.\n",
       "\n",
       "---\n",
       "\n",
       "## **Our Offerings**\n",
       "### **Models**\n",
       "Explore over 1 million models, including cutting-edge tools from industry leaders like Google, Microsoft, and Amazon. Our models encompass various modalities, including text, image, video, audio, and 3D.\n",
       "\n",
       "### **Datasets**\n",
       "Access and share more than 250,000 datasets tailored for every machine learning task. Join our community in building robust datasets to advance research.\n",
       "\n",
       "### **Spaces**\n",
       "Utilize our platforms Spaces to host and collaborate on applications, allowing users to generate and deploy applications quickly.\n",
       "\n",
       "### **Enterprise Solutions**\n",
       "With over 50,000 organizations leveraging our tools, we offer enterprise-grade security, access controls, and dedicated support to empower your team in building advanced AI solutions.\n",
       "\n",
       "- **Compute Services:** Start at $0.60/hour for GPU.\n",
       "- **Enterprise Pricing:** Starts at $20/user/month.\n",
       "\n",
       "---\n",
       "\n",
       "## **Community and Culture**\n",
       "At Hugging Face, we embrace a vibrant and engaged community committed to open-source values and collaboration. Our team ethos revolves around:\n",
       "\n",
       "- **Innovation:** Constantly evolving and improving through community feedback.\n",
       "- **Inclusivity:** Welcoming contributions from diverse backgrounds.\n",
       "- **Transparency:** Open discussions about our tools and technologies.\n",
       "\n",
       "Join our community on platforms like GitHub, Twitter, LinkedIn, and Discord to exchange ideas and grow together in AI!\n",
       "\n",
       "---\n",
       "\n",
       "## **Careers at Hugging Face**\n",
       "We are always on the lookout for passionate individuals to join our team. If you believe in the transformative power of AI and want to be part of a supportive and driven community, explore our job openings. We offer flexible work arrangements and a culture that prioritizes growth and innovation.\n",
       "\n",
       "---\n",
       "\n",
       "## **Join Us in Building the Future of AI**\n",
       "Discover the endless possibilities with Hugging Face. Whether you're a researcher, developer, or a business looking to implement AI solutions, we have the tools and community support you need. \n",
       "\n",
       "**Contact us today and start your journey with Hugging Face!**\n",
       "\n",
       "- **Website:** [huggingface.co](https://huggingface.co)\n",
       "- **Social Media:** [Twitter](https://twitter.com/huggingface) | [LinkedIn](https://www.linkedin.com/company/huggingface/)\n",
       "\n",
       "---\n",
       "\n",
       "*Hugging Face - The AI community building the future.*"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stream_brochure(\"HuggingFace\", \"https://huggingface.co\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb3f8d8-a3eb-41c8-b1aa-9f60686a653b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try changing the system prompt to the humorous version when you make the Brochure for Hugging Face:\n",
    "\n",
    "stream_brochure(\"HuggingFace\", \"https://huggingface.co\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d3e1a1-ba54-4907-97c5-30f89a24775b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
